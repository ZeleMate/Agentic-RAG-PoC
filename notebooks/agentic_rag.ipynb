{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bef23e9",
   "metadata": {},
   "source": [
    "## Agentic RAG â€“ Proof of Concept (LangGraph + FAISS + Hugging Face + Ollama)\n",
    "\n",
    "# Goal: arXiv paper -> chunks -> embeddings -> FAISS -> retrieve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa1856",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "This notebook is a minimal, local Agentic RAG proof-of-concept. The following cell installs only the packages required to:\n",
    "- load and chunk documents\n",
    "- embed chunks and build a FAISS vector index\n",
    "- run a local LLM via `init_chat_model` (e.g., Ollama)\n",
    "- orchestrate agentic control flow with LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11206043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (4.55.2)\n",
      "Requirement already satisfied: langgraph in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (0.6.5)\n",
      "Requirement already satisfied: langchain-community in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-text-splitters in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (0.3.9)\n",
      "Requirement already satisfied: langchain-ollama in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (0.3.6)\n",
      "Requirement already satisfied: langchain-huggingface in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (0.3.1)\n",
      "Requirement already satisfied: sentence-transformers in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (5.1.0)\n",
      "Requirement already satisfied: torch in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: langchain-docling in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: faiss-cpu in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (1.12.0)\n",
      "Requirement already satisfied: filelock in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
      "Requirement already satisfied: langchain-core>=0.1 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langgraph) (0.3.74)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langgraph) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langgraph) (0.6.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langgraph) (0.2.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.2)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langchain-community) (2.0.43)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langchain-community) (0.4.14)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.5.1 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langchain-ollama) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: Pillow in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: docling~=2.18 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langchain-docling) (2.44.0)\n",
      "Requirement already satisfied: docling-core<3.0.0,>=2.42.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling-core[chunking]<3.0.0,>=2.42.0->docling~=2.18->langchain-docling) (2.44.2)\n",
      "Requirement already satisfied: docling-parse<5.0.0,>=4.0.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (4.1.0)\n",
      "Requirement already satisfied: docling-ibm-models<4,>=3.9.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (3.9.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (1.2.0)\n",
      "Requirement already satisfied: pypdfium2!=4.30.1,<5.0.0,>=4.30.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (4.30.0)\n",
      "Requirement already satisfied: easyocr<2.0,>=1.7 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (1.7.2)\n",
      "Requirement already satisfied: rtree<2.0.0,>=1.3.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (1.4.1)\n",
      "Requirement already satisfied: typer<0.17.0,>=0.12.5 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (0.16.0)\n",
      "Requirement already satisfied: python-docx<2.0.0,>=1.1.2 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (1.2.0)\n",
      "Requirement already satisfied: python-pptx<2.0.0,>=1.0.2 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (1.0.2)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (4.13.4)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (2.3.1)\n",
      "Requirement already satisfied: marko<3.0.0,>=2.1.2 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (2.2.0)\n",
      "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (3.1.5)\n",
      "Requirement already satisfied: lxml<6.0.0,>=4.0.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (5.4.0)\n",
      "Requirement already satisfied: pluggy<2.0.0,>=1.0.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (1.6.0)\n",
      "Requirement already satisfied: pylatexenc<3.0,>=2.10 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (2.10)\n",
      "Requirement already satisfied: accelerate<2,>=1.0.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling~=2.18->langchain-docling) (1.10.0)\n",
      "Requirement already satisfied: psutil in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from accelerate<2,>=1.0.0->docling~=2.18->langchain-docling) (7.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling~=2.18->langchain-docling) (2.7)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling~=2.18->langchain-docling) (4.25.0)\n",
      "Requirement already satisfied: jsonref<2.0.0,>=1.1.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling~=2.18->langchain-docling) (1.1.0)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling~=2.18->langchain-docling) (0.9.0)\n",
      "Requirement already satisfied: latex2mathml<4.0.0,>=3.77.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling~=2.18->langchain-docling) (3.78.0)\n",
      "Requirement already satisfied: semchunk<3.0.0,>=2.2.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling-core[chunking]<3.0.0,>=2.42.0->docling~=2.18->langchain-docling) (2.2.2)\n",
      "Requirement already satisfied: torchvision<1,>=0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling-ibm-models<4,>=3.9.0->docling~=2.18->langchain-docling) (0.23.0)\n",
      "Requirement already satisfied: jsonlines<4.0.0,>=3.1.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling-ibm-models<4,>=3.9.0->docling~=2.18->langchain-docling) (3.1.0)\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.6.0.66 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from docling-ibm-models<4,>=3.9.0->docling~=2.18->langchain-docling) (4.12.0.88)\n",
      "Requirement already satisfied: scikit-image in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from easyocr<2.0,>=1.7->docling~=2.18->langchain-docling) (0.25.2)\n",
      "Requirement already satisfied: python-bidi in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from easyocr<2.0,>=1.7->docling~=2.18->langchain-docling) (0.6.6)\n",
      "Requirement already satisfied: Shapely in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from easyocr<2.0,>=1.7->docling~=2.18->langchain-docling) (2.1.1)\n",
      "Requirement already satisfied: pyclipper in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from easyocr<2.0,>=1.7->docling~=2.18->langchain-docling) (1.3.0.post6)\n",
      "Requirement already satisfied: ninja in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from easyocr<2.0,>=1.7->docling~=2.18->langchain-docling) (1.13.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling~=2.18->langchain-docling) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling~=2.18->langchain-docling) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling~=2.18->langchain-docling) (0.27.0)\n",
      "Requirement already satisfied: et-xmlfile in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from openpyxl<4.0.0,>=3.1.5->docling~=2.18->langchain-docling) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.4->docling~=2.18->langchain-docling) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.4->docling~=2.18->langchain-docling) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.4->docling~=2.18->langchain-docling) (2025.2)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from python-pptx<2.0.0,>=1.0.2->docling~=2.18->langchain-docling) (3.2.5)\n",
      "Requirement already satisfied: mpire[dill] in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.42.0->docling~=2.18->langchain-docling) (2.10.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from typer<0.17.0,>=0.12.5->docling~=2.18->langchain-docling) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from typer<0.17.0,>=0.12.5->docling~=2.18->langchain-docling) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from typer<0.17.0,>=0.12.5->docling~=2.18->langchain-docling) (14.1.0)\n",
      "Requirement already satisfied: anyio in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->docling~=2.18->langchain-docling) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<0.17.0,>=0.12.5->docling~=2.18->langchain-docling) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<0.17.0,>=0.12.5->docling~=2.18->langchain-docling) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.17.0,>=0.12.5->docling~=2.18->langchain-docling) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.42.0->docling~=2.18->langchain-docling) (0.70.16)\n",
      "Requirement already satisfied: dill>=0.3.8 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from multiprocess>=0.70.15->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.42.0->docling~=2.18->langchain-docling) (0.3.8)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from scikit-image->easyocr<2.0,>=1.7->docling~=2.18->langchain-docling) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from scikit-image->easyocr<2.0,>=1.7->docling~=2.18->langchain-docling) (2025.6.11)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from scikit-image->easyocr<2.0,>=1.7->docling~=2.18->langchain-docling) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Only run this cell if you are not using the environment with the dependencies installed from the pyproject.toml file\n",
    "\n",
    "%pip install -U \\\n",
    "  transformers \\\n",
    "  langgraph langchain-community langchain-text-splitters langchain-ollama langchain-huggingface\\\n",
    "  sentence-transformers \\\n",
    "  torch langchain-docling \\\n",
    "  faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b49efb6",
   "metadata": {},
   "source": [
    "## Imports and reproducibility\n",
    "We import only what is needed for a clear, reproducible baseline. A fixed random seed makes the pipeline deterministic for demonstration.\n",
    "\n",
    "Key points:\n",
    "- keep imports minimal (clarity over breadth)\n",
    "- set a global seed for `random` and `numpy`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05ef7120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045d916",
   "metadata": {},
   "source": [
    "## Document loading and chunking\n",
    "We use Docling to load a single arXiv PDF and split it into chunks suitable for embedding. Two export modes are supported:\n",
    "- `DOC_CHUNKS` (default): uses the loader's hybrid chunker\n",
    "- `MARKDOWN`: uses header-based splitting (shown for completeness)\n",
    "\n",
    "This step turns raw text into semantically meaningful pieces for retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d681ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/zelenyianszkimate/Documents/Agentic-RAG-PoC/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5188 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- d.page_content='A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures\\nDezhang Kong, Shi Lin, Zhenhua Xu, Zhebo Wang, Minghao Li, Yufeng Li, Yilun Zhang, Hujin Peng, Zeyang Sha, Yuyuan Li, Changting Lin, Xun Wang, Xuan Liu, Ningyu Zhang, Chaochao Chen, Muhammad Khurram Khan, Meng Han'\n",
      "- d.page_content='A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures\\nAbstract -In recent years, Large-Language-Model-driven AI agents have exhibited unprecedented intelligence and adaptability, and are rapidly changing human production and life. Nowadays, agents are undergoing a new round of evolution. They no longer act as an isolated island like LLMs. Instead, they start to communicate with diverse external entities, such as other agents and tools, to perform more complex tasks collectively. Under this trend, agent communication is regarded as a foundational pillar of the future AI ecosystem, and many organizations have intensively begun'\n",
      "- d.page_content=\"A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures\\nto design related communication protocols (e.g., Anthropic's MCP and Google's A2A) within the recent few months. However, this new field exposes significant security hazards, which can cause severe damage to real-world scenarios. To help researchers quickly figure out this promising topic and benefit the future agent communication development, this paper presents a comprehensive survey of agent communication security . More precisely, we first present a clear definition of agent communication and categorize the entire lifecycle of agent communication into\"\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "from docling.chunking import HybridChunker\n",
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "\n",
    "FILE_PATH = [\"https://arxiv.org/pdf/2506.19676\"]\n",
    "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "GEN_MODEL_ID = \"ollama:qwen3:4b\"\n",
    "EXPORT_TYPE = ExportType.DOC_CHUNKS\n",
    "\n",
    "loader = DoclingLoader(\n",
    "    file_path=FILE_PATH,\n",
    "    export_type=EXPORT_TYPE,\n",
    "    chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "if EXPORT_TYPE == ExportType.DOC_CHUNKS:\n",
    "    splits = docs\n",
    "elif EXPORT_TYPE == ExportType.MARKDOWN:\n",
    "    from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "    splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=[\n",
    "            (\"#\", \"Header_1\"),\n",
    "            (\"##\", \"Header_2\"),\n",
    "            (\"###\", \"Header_3\"),\n",
    "        ],\n",
    "    )\n",
    "    splits = [split for doc in docs for split in splitter.split_text(doc.page_content)]\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\")\n",
    "\n",
    "for d in splits[:3]:\n",
    "    print(f\"- {d.page_content=}\")\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e13af6d",
   "metadata": {},
   "source": [
    "## Vector store and retriever\n",
    "We embed the chunks with `sentence-transformers` and build a FAISS index. Then we expose a `retriever` and wrap it as a LangChain \"tool\" so the agent can decide to call it.\n",
    "\n",
    "Why FAISS?\n",
    "- fast, local approximate nearest-neighbor search\n",
    "- works well for PoC and small datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e99f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building FAISS index from documents...\n",
      "FAISS index size: 695\n",
      "Number of document chunks: 695\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL_ID)\n",
    "\n",
    "print(\"Building FAISS index from documents...\")\n",
    "vectorstore = FAISS.from_documents(splits, embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"arxiv_paper_retriever\",\n",
    "    \"Retrieves and answers the question about the arxiv paper\",\n",
    ")\n",
    "\n",
    "print(f\"FAISS index size: {vectorstore.index.ntotal}\")\n",
    "print(f\"Number of document chunks: {len(splits)}\")\n",
    "\n",
    "# If the index is empty, add documents:\n",
    "if vectorstore.index.ntotal == 0:\n",
    "    print(\"Populating the FAISS index...\")\n",
    "    vectorstore.add_documents(splits)\n",
    "    print(f\"FAISS index size after update: {vectorstore.index.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10685490",
   "metadata": {},
   "source": [
    "## Agentic decision: retrieve or respond\n",
    "We initialize a local chat model and define a function that lets the LLM decide autonomously whether to call the retriever tool or answer directly.\n",
    "\n",
    "This demonstrates agentic behavior: tool-use planning vs direct generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9f4164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "response_model = init_chat_model(GEN_MODEL_ID, temperature=0)\n",
    "\n",
    "\n",
    "def generate_query_or_respond(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Call the model to generate a response based on the current state.\n",
    "    The LLM will decide to use the retriever tool, or respond directly.\n",
    "    \"\"\"\n",
    "    response = response_model.bind_tools([retriever_tool]).invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68c25308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking about the main idea of an arXiv paper. But wait, they didn't specify which paper. Hmm, the function provided is arxiv_paper_retriever, which requires a query. Since the user didn't mention a specific paper title or ID, I can't retrieve the main idea without knowing which paper they're referring to.\n",
      "\n",
      "I should check the tools again. The function needs a \"query\" parameter. The user's question is too vague here. Maybe they expect me to ask for clarification, but according to the instructions, I need to call the function if possible. Wait, the problem says \"You may call one or more functions to assist with the user query.\" But in this case, without a specific query, the function can't be called properly.\n",
      "\n",
      "Wait, the user's message is \"What is the main idea of the arxiv paper?\" which is a bit unclear. They might have meant a specific paper but forgot to mention it. Since the function requires a query, I need to prompt the user for more details. However, the instructions say to return tool calls within the tool_call tags if I need to call a function. But in this case, I don't have enough info to call the function. So maybe I shouldn't make a tool call here and instead respond that the query is incomplete.\n",
      "\n",
      "Wait, the problem says \"For each function call, return a json object...\" but if I can't make a valid call, I should not output any tool_call. Wait, the user's instruction says \"You may call one or more functions to assist with the user query.\" So if the user's query is incomplete, I shouldn't call the function. Let me think.\n",
      "\n",
      "The function arxiv_paper_retriever needs a \"query\" parameter. The user didn't specify which paper, so the query is missing. Therefore, I can't call the function. The correct response here would be to inform the user that they need to specify which arXiv paper they're asking about. But according to the problem's instructions, I'm supposed to return tool calls if I need to use them. Since I can't, I shouldn't output any tool_call. Wait, but the problem says \"You may call one or more functions...\" so if I don't need to, then no tool calls.\n",
      "\n",
      "Wait, the user's question is too vague. The assistant should probably respond that they need more information. But the problem here is that the assistant is supposed to output tool calls if needed. Since the user didn't provide a specific query, the assistant can't call the function. Therefore, the correct action is not to make a tool call here. But the problem says \"For each function call...\" so if there's no function to call, then no tool_call tags.\n",
      "\n",
      "Wait, but the user might have intended to ask about a specific paper but forgot. However, the instructions say to use the tools provided. Since the function requires a query, and the user didn't provide one, I shouldn't call the function. So the answer here is that no tool call is made, and the assistant should respond with a message asking for the paper title or ID.\n",
      "\n",
      "But the problem says \"You may call one or more functions to assist with the user query.\" So in this case, since the user's query is incomplete, the assistant should not call any function. Therefore, the response should be a message to the user asking for more details. However, the problem's instructions here are to output tool calls within tool_call tags if needed. Since there's no valid query, no tool call is made.\n",
      "\n",
      "Wait, the problem says \"For each function call, return a json object...\" So if I don't need to call any function, then I don't output any tool_call. But the user's question is a bit ambiguous. Let me check the example again.\n",
      "\n",
      "The user says: \"What is the main idea of the arxiv paper?\" So they're asking about a paper, but without specifying which one. The arxiv_paper_retriever function needs a query. So the function can't be called without a specific query. Therefore, the correct response is to inform the user that they need to specify which paper they're referring to. But according to the problem's instructions, the assistant is supposed to output tool calls if they need to use the functions. Since they don't have enough info, no tool call is made.\n",
      "\n",
      "So in this case, the answer is no tool calls. But the problem says \"You may call one or more functions...\" so if I don't call any, then the response is just a message. However, the problem here is that the user is expecting the assistant to output tool calls if needed. Since it's not needed here, the assistant should not output any tool_call tags.\n",
      "\n",
      "Wait, but the problem says \"For each function call, return a json object...\" So if there's no function call, then no tool_call tags. So the answer here is that there's no tool call to make. Therefore, the assistant should respond with a message asking for the specific paper.\n",
      "\n",
      "But the problem is structured such that the assistant's response should be either tool calls or a final answer. Wait, the problem says \"You may call one or more functions to assist with the user query.\" So in this case, the assistant should respond with a message to the user, not a tool call.\n",
      "\n",
      "But according to the problem's instructions, the assistant is supposed to output tool calls within tool_call tags if they need to call a function. Since they don't have enough info, they shouldn't call the function. Therefore, the correct response here is no tool calls, and the assistant would then generate a message to the user.\n",
      "\n",
      "But the problem here is that the user's question is part of the input, and the assistant needs to output either tool calls or a final answer. Wait, the problem says \"You may call one or more functions to assist with the user query.\" So the assistant's response should be either tool calls or a final answer.\n",
      "\n",
      "In this case, since the user didn't specify the paper, the assistant can't call the function, so the assistant should respond with a message. But the problem's instructions here are to output tool calls if needed. So the answer here is no tool calls.\n",
      "\n",
      "Wait, but the problem says \"For each function call, return a json object...\" So if there's no function call, then no tool_call tags. Therefore, the assistant's response here is to not output any tool_call tags and instead provide a message. However, the problem's context is that the assistant is supposed to output tool calls within tool_call tags when needed. Since it's not needed here, the answer is no tool calls.\n",
      "\n",
      "But the user's question is a bit unclear. Let me re-read the problem statement.\n",
      "\n",
      "The user says: \"What is the main idea of the arxiv paper?\"\n",
      "\n",
      "The function arxiv_paper_retriever requires a query. The user didn't specify which paper, so the query is missing. Therefore, the assistant cannot call the function. So the correct action is to not make a tool call and instead ask the user for more details.\n",
      "\n",
      "But according to the problem's instructions, the assistant is supposed to output tool calls if they need to call functions. Since they don't need to here, there's no tool call. So the answer is no tool calls.\n",
      "\n",
      "Therefore, the response should be that there's no tool call to make. But the problem says \"For each function call...\" so if there's none, then no tool_call tags.\n",
      "\n",
      "So in this case, the assistant would output nothing in the tool_call tags. But the problem might expect the assistant to respond with a message. However, the problem's instructions here are to output tool calls if needed. So the answer here is no tool calls.\n",
      "</think>\n",
      "\n",
      "The user's query is incomplete as they did not specify which arXiv paper they are referring to. The function `arxiv_paper_retriever` requires a specific query (e.g., paper title, ID, or keywords) to retrieve information. Without this detail, no valid function call can be made. \n",
      "\n",
      "<response>\n",
      "I need more information to help you. Could you please specify which arXiv paper you're asking about? For example, provide the paper title, author names, or arXiv ID.\n",
      "</response>\n"
     ]
    }
   ],
   "source": [
    "# Check if the retriever tool is working\n",
    "\n",
    "\n",
    "input = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the main idea of the arxiv paper?\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "generate_query_or_respond(input)[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20fbfbb",
   "metadata": {},
   "source": [
    "## Relevance grading\n",
    "We add a lightweight, LLM-based grader that checks if retrieved context is relevant to the user question.\n",
    "\n",
    "Outputs a binary decision that controls the next step:\n",
    "- relevant -> generate answer\n",
    "- not relevant -> rewrite question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91850382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# GRADE_PROMPT â€“ binary relevance grader (returns yes/no)\n",
    "\n",
    "GRADE_PROMPT = (\n",
    "    \"You are an expert RAG evaluator. Decide if the retrieved CONTEXT is \"\n",
    "    \"useful to answer the USER QUESTION.\\n\\n\"\n",
    "    \"Evaluation rubric (relevant = 'yes'):\\n\"\n",
    "    \"- The context contains facts, definitions, steps, or terminology that directly support answering the question.\\n\"\n",
    "    \"- The context matches the semantic intent (not just surface keywords).\\n\"\n",
    "    \"- Minor wording differences are acceptable if the meaning aligns.\\n\"\n",
    "    \"Irrelevant = 'no' when the context is off-topic, purely generic, or lacks the key facts needed.\\n\\n\"\n",
    "    \"USER QUESTION:\\n{question}\\n\\n\"\n",
    "    \"CONTEXT:\\n{context}\\n\\n\"\n",
    "    \"Answer strictly with 'yes' or 'no'.\"\n",
    ")\n",
    "\n",
    "\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"Grade documents using a binary score for relevance check.\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Relevance score: 'yes' if relevant, or 'no' if not relevant\"\n",
    "    )\n",
    "\n",
    "\n",
    "grader_model = init_chat_model(\"ollama:qwen3:4b\", temperature=0)\n",
    "\n",
    "\n",
    "def grade_documents(\n",
    "    state: MessagesState,\n",
    ") -> Literal[\"generate_answer\", \"rewrite_question\"]:\n",
    "    \"\"\"Determine whether the retrieved documents are relevant to the question.\n",
    "    Input:\n",
    "    - question: str\n",
    "    - context: str\n",
    "    Output:\n",
    "    - binary_score: str\n",
    "\n",
    "    \"\"\"\n",
    "    question = state[\"messages\"][0].content\n",
    "    context = state[\"messages\"][-1].content\n",
    "\n",
    "    prompt = GRADE_PROMPT.format(question=question, context=context)\n",
    "    response = grader_model.with_structured_output(GradeDocuments).invoke(\n",
    "        [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    score = response.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        return \"generate_answer\"\n",
    "    else:\n",
    "        return \"rewrite_question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d258b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rewrite_question'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the grader function is working for rewriting the question\n",
    "\n",
    "\n",
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "input = {\n",
    "    \"messages\": convert_to_messages(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What are the main limitations of the current agent protocols?\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"1\",\n",
    "                        \"name\": \"retrieve_blog_posts\",\n",
    "                        \"args\": {\"query\": \"types of reward hacking\"},\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\"role\": \"tool\", \"content\": \"something else\", \"tool_call_id\": \"1\"},\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "grade_documents(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e733c649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'generate_answer'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the grade documents function is working for generating an answer\n",
    "\n",
    "input = {\n",
    "    \"messages\": convert_to_messages(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the main idea of the paper?\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"1\",\n",
    "                        \"name\": \"arxiv_paper_retriever\",\n",
    "                        \"args\": {\"query\": \"paper main idea\"},\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": \"The main idea of the paper is that agent communication is a new and promising research field.\",\n",
    "                \"tool_call_id\": \"1\",\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "grade_documents(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8cfd2c",
   "metadata": {},
   "source": [
    "## Question rewriting\n",
    "If context is not relevant, the agent rewrites the user question to better capture the intended meaning and improve retrieval on the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839cf122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# REWRITE_PROMPT â€“ intent-preserving question rewrite to improve\n",
    "\n",
    "REWRITE_PROMPT = (\n",
    "    \"Rewrite the user's question to maximize retrieval quality while preserving intent.\\n\"\n",
    "    \"Guidelines:\\n\"\n",
    "    \"- Keep it specific and unambiguous; include essential entities, time ranges, and constraints.\\n\"\n",
    "    \"- Remove vague words; prefer domain terms from the original question when helpful.\\n\"\n",
    "    \"- Keep it a single, self-contained question; do not add new information.\\n\\n\"\n",
    "    \"Original question:\\n-------\\n{question}\\n-------\\n\"\n",
    "    \"Improved question:\"\n",
    ")\n",
    "\n",
    "\n",
    "def rewrite_question(state: MessagesState):\n",
    "    \"\"\"Rewrite the original user question.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    prompt = REWRITE_PROMPT.format(question=question)\n",
    "    response = response_model.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "    return {\"messages\": [HumanMessage(content=response.content)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d97e07ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "We are given the original question: \"What is the main idea of the paper?\"\n",
      " The goal is to rewrite it to maximize retrieval quality while preserving intent.\n",
      "\n",
      " Guidelines:\n",
      " - Keep it specific and unambiguous; include essential entities, time ranges, and constraints.\n",
      " - Remove vague words; prefer domain terms from the original question when helpful.\n",
      " - Keep it a single, self-contained question; do not add new information.\n",
      "\n",
      " Analysis of the original question:\n",
      "   - The question is about the \"main idea\" of a \"paper\".\n",
      "   - However, the original question does not specify which paper. This is vague because there are many papers.\n",
      "\n",
      " Problem: Without knowing which paper, the question is too broad and cannot be retrieved effectively.\n",
      "\n",
      " How to improve?\n",
      "   - We must include the essential entity: the paper. But the original question doesn't specify which paper.\n",
      "   - Since the user didn't specify a paper, we have to assume that in the context of the conversation or the system, there might be a specific paper in mind? \n",
      "     However, the instructions say: do not add new information. So we cannot assume a paper.\n",
      "\n",
      " Alternative approach:\n",
      "   - The problem states: \"maximize retrieval quality\". In a typical retrieval system (like a search engine or a database), we need to be specific.\n",
      "\n",
      " But note: the original question is from a user who might be referring to a paper that was previously mentioned? However, the problem says: do not add new information.\n",
      "\n",
      " Since the original question does not specify a paper, we have two options:\n",
      "   Option 1: Assume that the system context already has a paper in mind (like in a conversation) and then the question becomes specific? But the problem says: do not add new information.\n",
      "\n",
      "   Option 2: The improved question must be as specific as possible without adding new information. However, the original question is too vague.\n",
      "\n",
      " Let's think about what the user might have intended. In many contexts, when someone asks \"What is the main idea of the paper?\" they are referring to a specific paper that they have in mind (e.g., the last paper they read, or a paper they are currently working on). But without that context, we cannot know.\n",
      "\n",
      " However, the problem says: \"preserving intent\". The intent is to get the main idea of a paper. But without the paper, we cannot answer.\n",
      "\n",
      " How can we rewrite without adding new information?\n",
      "   - We cannot add the paper title or author because the original question doesn't have it.\n",
      "\n",
      " But note: the guidelines say \"include essential entities\". The essential entity here is the paper. Since the user didn't specify, we have to leave it as a placeholder? \n",
      "\n",
      " However, the problem says: \"do not add new information\". So we cannot invent a paper.\n",
      "\n",
      " Another idea: In some systems, the user might be interacting with a system that has a current context (like a paper that was uploaded or the last paper in the conversation). But the problem doesn't specify that.\n",
      "\n",
      " Given the constraints, the best we can do is to make the question as specific as the original without adding anything. But the original is too vague.\n",
      "\n",
      " Let me re-read the guidelines: \"Keep it specific and unambiguous\". The original is not specific. So we have to make it more specific? But we don't have extra information.\n",
      "\n",
      " Alternative: The problem might be that in the context of the system, there is a paper that is the subject of the conversation. However, the problem says: do not add new information. So we cannot assume.\n",
      "\n",
      " After careful thought, I think the intended solution is to recognize that the original question is too vague and we must force it to be specific by including the fact that it's about the current paper (if the system has a context) but without adding new information, we cannot.\n",
      "\n",
      " However, note the problem says: \"Rewrite the user's question\". The user's question is \"What is the main idea of the paper?\".\n",
      "\n",
      " Since the user didn't specify which paper, the improved question should still be the same? But that doesn't maximize retrieval quality.\n",
      "\n",
      " Let me look for standard practices in information retrieval:\n",
      "\n",
      "   - In a search engine, if you want to get the main idea of a paper, you would need to specify the paper.\n",
      "\n",
      "   - But the problem says: do not add new information.\n",
      "\n",
      " Therefore, the improved question must be the same as the original? But that doesn't seem to maximize retrieval quality.\n",
      "\n",
      " Another angle: The problem might be that the user is in a context where the paper is already known (e.g., the system has a paper object). In that case, the question becomes: \"What is the main idea of the current paper?\".\n",
      "\n",
      " However, the problem says: do not add new information. So we cannot say \"current\" because that's new.\n",
      "\n",
      " How about: We rewrite the question to be more precise by using the term \"paper\" as a domain term? But the original already uses \"paper\".\n",
      "\n",
      " After careful thought, I think the problem expects us to realize that without a specific paper, the question is unanswerable. But the instruction is to rewrite the question to maximize retrieval quality.\n",
      "\n",
      " Since we cannot add a paper title, we have to leave it as is? But the guidelines say to make it specific and unambiguous.\n",
      "\n",
      " Let me try to see if there's a way without adding new information:\n",
      "\n",
      "   Original: \"What is the main idea of the paper?\"\n",
      "\n",
      "   We can rewrite it as: \"What is the main idea of the paper?\" -> but that's the same.\n",
      "\n",
      "   However, the problem says: \"maximize retrieval quality\". In a system that has a paper in context, the system might interpret \"the paper\" as the current paper. But without context, it's vague.\n",
      "\n",
      "   Given the constraints, I think the best we can do is to keep the question as is? But that doesn't seem to follow the guideline of being specific.\n",
      "\n",
      "   Alternatively, the problem might be that the user intended to refer to a specific paper that was previously mentioned in the conversation? But the problem doesn't say that.\n",
      "\n",
      "   Since the problem says: \"do not add new information\", we cannot change the question to include a paper title.\n",
      "\n",
      "   Therefore, the improved question is the same as the original? But that doesn't maximize retrieval quality.\n",
      "\n",
      "   However, note: the problem says \"Rewrite the user's question\". We are allowed to rephrase to be more specific without adding new information? But the original is already specific? \n",
      "\n",
      "   Wait, the original is not specific because it doesn't say which paper.\n",
      "\n",
      "   But the problem says: \"include essential entities\". The essential entity is the paper. We don't have it.\n",
      "\n",
      "   I think the intended answer here is to realize that without a specific paper, the question is unanswerable. But the problem asks for a rewrite that preserves intent.\n",
      "\n",
      "   After reading the problem again: \"maximize retrieval quality\". In a retrieval system, if we don't specify the paper, the system might return multiple papers. So we want to avoid that.\n",
      "\n",
      "   How about: We rewrite the question to be more precise by using the term \"the paper\" (implying the current context) without adding new information? But the problem says: do not add new information.\n",
      "\n",
      "   I found a solution in the literature: In some systems, when the user says \"the paper\", it refers to the paper that was just discussed. But without context, we can't.\n",
      "\n",
      "   Given the strict constraints, I think the problem expects us to output the same question? But that doesn't seem to be maximizing retrieval quality.\n",
      "\n",
      "   Let me try to think of what the problem might be testing.\n",
      "\n",
      "   Another idea: The problem says \"preserving intent\". The intent is to get the main idea of a paper. We can rephrase to be more precise by using the term \"paper\" as a domain term? But it's already a domain term.\n",
      "\n",
      "   I think the answer is: We cannot make it more specific without adding information. So we leave it as is? But the problem says \"maximize retrieval quality\", so we want to be as specific as possible.\n",
      "\n",
      "   However, the guidelines say: \"Remove vague words\". The word \"the\" is vague? Actually, the vagueness is the lack of a specific paper.\n",
      "\n",
      "   Since we cannot add a paper title, we have to accept that the question is vague. But the problem says: \"maximize retrieval quality\". So we might have to make it as specific as we can without adding information.\n",
      "\n",
      "   I propose: The improved question is: \"What is the main idea of the paper?\" -> but that's the same.\n",
      "\n",
      "   Wait, the problem says: \"Rewrite\". So we can rephrase the sentence to be more precise? But without adding information, we can't.\n",
      "\n",
      "   After careful thought, I think the problem might be that in the context of the system, there is a paper that is the subject of the conversation. So the improved question is: \"What is the main idea of the paper?\" (same) but we can add a constraint that it's the current paper? But we cannot add new information.\n",
      "\n",
      "   Given the above, I decide to output the same question because we cannot add new information and we don't have the paper title.\n",
      "\n",
      "   However, the problem says: \"maximize retrieval quality\". In practice, if the system has a paper in context, then the question is specific enough. So we don't change it.\n",
      "\n",
      "   But note: the problem says \"include essential entities\". The essential entity is the paper. We don't have it, so we leave it as \"the paper\" (which is a common way to refer to the current paper in context).\n",
      "\n",
      "   Therefore, the improved question is: \"What is the main idea of the paper?\"\n",
      "\n",
      "   However, the problem says: \"Remove vague words\". The word \"the\" might be considered vague? But in English, \"the paper\" in context usually refers to one specific paper.\n",
      "\n",
      "   Alternatively, we can write: \"What is the main idea of the paper?\" -> but that's the same.\n",
      "\n",
      "   I think the answer is the same.\n",
      "\n",
      "   But wait, the problem says: \"maximize retrieval quality\". If we rewrite it to be more specific by using the term \"the paper\" (which is a common term in academic contexts to refer to the paper being discussed), then it's already specific enough.\n",
      "\n",
      "   So I'll go with: \"What is the main idea of the paper?\"\n",
      "\n",
      "   However, the problem says: \"Keep it specific and unambiguous\". The original is ambiguous because it doesn't specify which paper. But in the context of the conversation, it's unambiguous.\n",
      "\n",
      "   Given the constraints, I think the improved question is the same.\n",
      "\n",
      "   But let me see if there's a standard way.\n",
      "\n",
      "   Another thought: In some systems, the user might have uploaded a paper. Then the question is about that paper. So the question is specific.\n",
      "\n",
      "   Therefore, I conclude: The improved question is the same as the original.\n",
      "\n",
      "   However, the problem says: \"Rewrite\". So we are allowed to rephrase? But without adding information, we can't change the meaning.\n",
      "\n",
      "   I think the answer is: \"What is the main idea of the paper?\"\n",
      "\n",
      "   But wait, the problem says: \"maximize retrieval quality\". If we rewrite it to be more precise by using the term \"the paper\" (which is a standard term in academic contexts for the paper being discussed), then it's already good.\n",
      "\n",
      "   So I'll output: \"What is the main idea of the paper?\"\n",
      "\n",
      "   However, the problem might expect a different answer because the original is too vague.\n",
      "\n",
      "   Let me check the guidelines again: \"Keep it specific and unambiguous\". The original is not specific. So we have to make it specific? But we don't have the paper title.\n",
      "\n",
      "   I think the problem is designed to have us recognize that without a specific paper, we cannot make it specific. So we leave it as is.\n",
      "\n",
      "   Final decision: The improved question is the same as the original.\n",
      "\n",
      "   But note: the problem says \"Rewrite\". So we are not changing it? That seems odd.\n",
      "\n",
      "   Alternative: In the context of the system, the paper might be identified by a unique identifier. But the user didn't provide it.\n",
      "\n",
      "   Given the instructions, I think the answer is: \"What is the main idea of the paper?\"\n",
      "\n",
      "   However, I recall that in some retrieval systems, they use the term \"the paper\" to mean the paper that was just discussed. So it's acceptable.\n",
      "\n",
      "   Let's write it as: \"What is the main idea of the paper?\"\n",
      "\n",
      "   But the problem says: \"do not add new information\". We are not adding anything.\n",
      "\n",
      "   So I'll go with that.\n",
      "\n",
      "   However, the problem says: \"maximize retrieval quality\". If the system has a paper in context, then this question will be retrieved as the current paper. If not, then it's vague. But we have to work with what we have.\n",
      "\n",
      "   Therefore, the improved question is: \"What is the main idea of the paper?\"\n",
      "\n",
      "   But wait, the problem says: \"include essential entities\". We have the entity \"paper\", but we don't have a specific one. So it's not specific.\n",
      "\n",
      "   I think the problem might be expecting us to realize that we need to specify the paper. But we can't.\n",
      "\n",
      "   After re-thinking, I found a solution: In the context of the conversation, the user might have referred to a paper in a previous message. But the problem doesn't say that.\n",
      "\n",
      "   Given the strict constraints, I output the same.\n",
      "\n",
      "   However, the problem says: \"Rewrite\". So we can rephrase the sentence to be more precise? For example, we can say: \"What is the main idea of the paper?\" -> but that's the same.\n",
      "\n",
      "   I think the answer is: \"What is the main idea of the paper?\"\n",
      "\n",
      "   Let me see if there's a way to make it more specific without adding information? \n",
      "\n",
      "   We can use the term \"this paper\" to imply the current context? But the problem says: do not add new information. The word \"this\" is new? \n",
      "\n",
      "   The original says \"the paper\", so we can change to \"this paper\" to be more specific? But that adds the word \"this\", which is a new word? \n",
      "\n",
      "   However, in the context of the conversation, \"this paper\" refers to the paper that was just discussed. And it's a common way to be specific.\n",
      "\n",
      "   But the problem says: \"do not add new information\". The word \"this\" is not new information? It's a pronoun that refers to the current context.\n",
      "\n",
      "   Let me check: The original question uses \"the paper\". We are changing to \"this paper\". Is that adding new information? \n",
      "\n",
      "   In English, \"this\" is a demonstrative pronoun that is used to refer to something specific in the current context. It's not adding new information because it's part of the language.\n",
      "\n",
      "   However, the problem says: \"do not add new information\". The information that \"this\" implies is that the paper is the one being discussed now. But the original question didn't have that context. \n",
      "\n",
      "   But the problem says: \"preserving intent\". The intent is to get the main idea of the paper that the user is currently talking about. So it's the same intent.\n",
      "\n",
      "   And the guidelines say: \"Remove vague words\". The word \"the\" might be vague because it doesn't specify which paper, but \"this\" is more specific.\n",
      "\n",
      "   So I think: \"What is the main idea of this paper?\"\n",
      "\n",
      "   Why is this better?\n",
      "     - It's more specific: it refers to the paper that is currently in the conversation (the one the user is talking about).\n",
      "     - It doesn't add new information: we are just using a pronoun that is standard in conversational English to refer to the current context.\n",
      "\n",
      "   But note: the problem says \"do not add new information\". The word \"this\" is not new information? It's a word that has been used in English for a long time. And it doesn't add a new fact about the paper.\n",
      "\n",
      "   Also, the problem says: \"prefer domain terms from the original question\". The original question has \"paper\", and \"this\" is a common term in the context of academic discussions.\n",
      "\n",
      "   Let me see if this is acceptable.\n",
      "\n",
      "   In academic writing, we often say \"this paper\" to refer to the paper being discussed.\n",
      "\n",
      "   Example: In a paper, you might say: \"This paper presents ...\".\n",
      "\n",
      "   So I think this rewrite is better.\n",
      "\n",
      "   Steps:\n",
      "     - Original: \"What is the main idea of the paper?\"\n",
      "     - Improved: \"What is the main idea of this paper?\"\n",
      "\n",
      "   Why is it more specific and unambiguous?\n",
      "     - \"this paper\" is unambiguous in the context of the conversation (it refers to the paper that was just mentioned or the current topic).\n",
      "     - It removes the vagueness of \"the paper\" (which could be any paper).\n",
      "\n",
      "   And we are not adding new information: we are just changing \"the\" to \"this\", which is a standard way to be specific in conversation.\n",
      "\n",
      "   Also, it's a single, self-contained question.\n",
      "\n",
      "   Therefore, I choose: \"What is the main idea of this paper?\"\n",
      "\n",
      "   Let me check the guidelines:\n",
      "     - Specific and unambiguous: Yes, because it refers to the current paper in context.\n",
      "     - Remove vague words: The word \"the\" is vague (it doesn't specify which paper), so we remove it by using \"this\" (which is more specific).\n",
      "     - Prefer domain terms: In academic contexts, \"this paper\" is a common term.\n",
      "\n",
      "   This seems to maximize retrieval quality because the system will now look for the main idea of the paper that is the subject of the current conversation.\n",
      "\n",
      "   So the improved question is: \"What is the main idea of this paper?\"\n",
      "\n",
      "   But note: the problem says \"do not add new information\". We are not adding new information about the paper, just a pronoun that is standard.\n",
      "\n",
      "   I think this is the answer.\n",
      "\n",
      "   However, what if the system doesn't have a current paper? Then it's still vague. But the problem says: preserve intent. The intent is to get the main idea of the paper that the user is currently discussing.\n",
      "\n",
      "   Given the above, I'll go with: \"What is the main idea of this paper?\"\n",
      "\n",
      "   Let's write it.\n",
      "\n",
      "   Final answer: \"What is the main idea of this paper?\"\n",
      "</think>\n",
      "\n",
      "What is the main idea of this paper?\n"
     ]
    }
   ],
   "source": [
    "# Check if the rewrite question function is working\n",
    "\n",
    "\n",
    "input = {\n",
    "    \"messages\": convert_to_messages(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the main idea of the paper?\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"1\",\n",
    "                        \"name\": \"arxiv_paper_retriever\",\n",
    "                        \"args\": {\"query\": \"paper main idea\"},\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\"role\": \"tool\", \"content\": \"meow\", \"tool_call_id\": \"1\"},\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "response = rewrite_question(input)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c422fd37",
   "metadata": {},
   "source": [
    "## Answer generation\n",
    "Given a user question and relevant context, the model produces a concise answer.\n",
    "\n",
    "Principles:\n",
    "- be faithful to provided context\n",
    "- be brief and clear; admit when unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a52d026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# GENERATE_PROMPT â€“ grounded answer generation from provided context\n",
    "\n",
    "GENERATE_PROMPT = (\n",
    "    \"You are a concise, trustworthy assistant for Retrieval-Augmented QA.\\n\"\n",
    "    \"Instructions:\\n\"\n",
    "    \"- Use only the information in CONTEXT. Do not invent facts.\\n\"\n",
    "    '- If the answer is not found, say: \"I don\\'t know based on the provided context.\"\\n'\n",
    "    \"- Prefer 2â€“4 clear sentences. Use bullet points only if enumerating items.\\n\"\n",
    "    \"- Be faithful to the source; avoid speculation.\\n\\n\"\n",
    "    \"QUESTION:\\n{question}\\n\\n\"\n",
    "    \"CONTEXT:\\n{context}\\n\\n\"\n",
    "    \"Final answer:\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_answer(state: MessagesState):\n",
    "    \"\"\"Generate an answer for a given question with the provided context.\n",
    "    Input:\n",
    "    - question: str\n",
    "    - context: str\n",
    "    - prompt: str\n",
    "    Output:\n",
    "    - answer: str\n",
    "    \"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "\n",
    "    question = state[\"messages\"][0].content\n",
    "    context = state[\"messages\"][-1].content\n",
    "    prompt = GENERATE_PROMPT.format(question=question, context=context)\n",
    "\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\") or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    response = response_model.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d099069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Hmm, the user is asking about the main idea of a paper, and they've provided some retrieved context. Let me look at that context carefully.\n",
      "\n",
      "The context describes a paper that defines agent communication and categorizes its lifecycle into three stages: user-agent interaction, agent-agent communication, and agent-environment communication. It then analyzes security risks for each phase and discusses defense countermeasures. There's also mention of experiments using MCP and A2A protocols to identify vulnerabilities.\n",
      "\n",
      "I need to distill this into the main idea in three sentences max. The core seems to be about how the paper systematically examines agent communication security across different phases, identifies risks, and proposes defenses. \n",
      "\n",
      "The user probably wants a concise academic summary - maybe they're a researcher or student working on agent systems security. I should avoid jargon where possible while staying precise. \n",
      "\n",
      "Okay, I'll craft a response that captures: 1) the three-stage lifecycle framework 2) risk analysis per phase 3) defense countermeasures. Must keep it under three sentences as instructed. \n",
      "\n",
      "*checks word count* The draft I'm thinking of is: \"The paper defines agent communication and categorizes its lifecycle into three stages (user-agent, agent-agent, agent-environment). It analyzes security risks for each phase and proposes defense countermeasures. Additionally, it uses experiments with MCP and A2A protocols to identify vulnerabilities in agent communication systems.\" \n",
      "\n",
      "That's exactly three sentences and covers all key points without fluff. Perfect for the user's request.\n",
      "</think>\n",
      "\n",
      "The paper defines agent communication and categorizes its lifecycle into three stages: user-agent interaction, agent-agent communication, and agent-environment communication. It analyzes security risks for each phase and proposes defense countermeasures. Additionally, it uses experiments with MCP and A2A protocols to identify vulnerabilities in agent communication systems.\n"
     ]
    }
   ],
   "source": [
    "# Check if the answer generation function is working\n",
    "\n",
    "\n",
    "input = {\n",
    "    \"messages\": convert_to_messages(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the main idea of the paper?\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"1\",\n",
    "                        \"name\": \"arxiv_paper_retriever\",\n",
    "                        \"args\": {\"query\": \"paper main idea\"},\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": \"More precisely, we first present a clear definition of agent communication and categorize the entire lifecycle of agent communication into three stages: user-agent interaction, agent-agent communication, and agent-environment communication. Next, for each communication phase, we dissect related protocols and analyze the security risks according to the communication characteristics. Then, we summarize and outlook on the possible defense countermeasures for each risk. In addition, we conduct experiments using MCP and A2A to help readers better understand the novel vulnerabilities brought by agent communication. Finally, we discuss open issues and future directions in this promising research field.\",\n",
    "                \"tool_call_id\": \"1\",\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "response = generate_answer(input)\n",
    "response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8d00ae",
   "metadata": {},
   "source": [
    "## Agent workflow (LangGraph)\n",
    "We compose the functions into a small state graph. The flow is:\n",
    "1. decide (respond or use tool)\n",
    "2. if tool used -> grade relevance\n",
    "3. if relevant -> generate answer; else -> rewrite question and loop\n",
    "\n",
    "The graph makes the agent's control flow explicit and inspectable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f35a67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(generate_query_or_respond)\n",
    "workflow.add_node(\"retrieve\", ToolNode([retriever_tool]))\n",
    "workflow.add_node(rewrite_question)\n",
    "workflow.add_node(generate_answer)\n",
    "\n",
    "workflow.add_edge(START, \"generate_query_or_respond\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_query_or_respond\",\n",
    "    # Assess LLM decision (call `retriever_tool` tool or respond to the user)\n",
    "    tools_condition,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Edges taken after the `action` node is called.\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # Assess agent decision\n",
    "    grade_documents,\n",
    ")\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "workflow.add_edge(\"rewrite_question\", \"generate_query_or_respond\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c1d9f9",
   "metadata": {},
   "source": [
    "## Visualize the workflow\n",
    "We render the compiled state graph to verify the structure and for easy explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d1d3955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a935c131",
   "metadata": {},
   "source": [
    "## Streaming the run\n",
    "We stream node updates to observe the agent's decisions step-by-step. This helps debug and explain the agentic behavior in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d9c4fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the main contribution of the 'A Survey of LLM-Driven AI Agent Communication' paper?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, let me try to figure out how to approach this. The user is asking about the main contribution of a specific paper titled \"A Survey of LLM-Driven AI Agent Communication\". \n",
      "\n",
      "First, I need to check if there's a paper with that exact title in the arXiv database. The user mentioned it's a survey paper, so it's likely a recent one. But in the previous interactions, the assistant used the arxiv_paper_retriever function to get information about AI agent communication papers. The tool response from earlier shows references to papers like [318] by Yingxuan Yang et al. (arXiv:2504.16736) titled \"A survey of ai agent protocols\" and [204] by Erik Miehling et al. (arXiv:2503.00237) titled \"Agentic ai needs a systems theory\".\n",
      "\n",
      "Wait, the user's current question is about \"A Survey of LLM-Driven AI Agent Communication\". The previous tool response mentions a paper by Yang et al. that's a survey of AI agent protocols (arXiv:2504.16736). But the user's title has \"LLM-Driven\" which might be a newer paper. However, the arXiv preprint from Yang et al. (2025) is a survey of AI agent protocols, not specifically LLM-driven.\n",
      "\n",
      "Hmm, the user might be conflating the title. The previous tool response shows that the paper [318] is titled \"A survey of ai agent protocols\" (arXiv:2504.16736). The user's question has \"LLM-Driven\" which isn't in the title of that paper. So maybe the user is referring to a different paper, but the tool response doesn't have a paper with \"LLM-Driven\" in the title.\n",
      "\n",
      "Wait, the problem says that the assistant can call the arxiv_paper_retriever function. The user is asking for the main contribution of that specific paper. But the tool response from the previous call shows that the paper [318] is a survey of AI agent protocols. The user's title has \"LLM-Driven\", which might be a mistake or a different paper.\n",
      "\n",
      "I need to check if there's a paper with that exact title. But since the tool response from the previous call doesn't include it, maybe the user is referring to the Yang et al. paper but with a slightly different title. Alternatively, the \"LLM-Driven\" part might be a recent addition.\n",
      "\n",
      "The assistant's job is to call the arxiv_paper_retriever with the query. The user's query is: \"What is the main contribution of the 'A Survey of LLM-Driven AI Agent Communication' paper?\"\n",
      "\n",
      "So the correct tool call would be to use the arxiv_paper_retriever with that query. But the previous tool response shows that the paper [318] is a survey of AI agent protocols (without LLM-Driven). So maybe the user's title is slightly off, but the assistant should still use the query as given.\n",
      "\n",
      "Wait, the problem says: \"You may call one or more functions to assist with the user query.\" So the assistant should generate a tool call for the arxiv_paper_retriever with the user's query.\n",
      "\n",
      "The user's query is: \"What is the main contribution of the 'A Survey of LLM-Driven AI Agent Communication' paper?\"\n",
      "\n",
      "So the tool call should be:\n",
      "\n",
      "{\n",
      "  \"name\": \"arxiv_paper_retriever\",\n",
      "  \"arguments\": {\n",
      "    \"query\": \"What is the main contribution of the 'A Survey of LLM-Driven AI Agent Communication' paper?\"\n",
      "  }\n",
      "}\n",
      "\n",
      "But in the previous interactions, the assistant used the tool with a slightly rephrased query. However, the user now specified the exact title with quotes. The assistant should use the query as the user provided it, but maybe adjust to be more precise without adding info.\n",
      "\n",
      "Wait, the guidelines say: \"rewrite it to maximize retrieval quality while preserving intent\". So the assistant should rephrase the query to be more specific and unambiguous.\n",
      "\n",
      "The user's query has a title in quotes: 'A Survey of LLM-Driven AI Agent Communication'. The problem is that the title might not exist exactly, but the assistant should try to make the query as specific as possible.\n",
      "\n",
      "In the previous example, the assistant rephrased to \"What is the main contribution of the paper on AI agent communication?\" to remove vagueness. Now, the user has a specific title, so the query should be more precise.\n",
      "\n",
      "But the user's title includes \"LLM-Driven\", which is a specific term. So the best rewrite would be to use the exact title as given, but maybe remove the quotes and make it a standard query.\n",
      "\n",
      "Wait, the problem says: \"include essential entities, time ranges, and constraints\". The essential entity here is the paper title. So the query should be: \"What is the main contribution of the paper titled 'A Survey of LLM-Driven AI Agent Communication'?\"\n",
      "\n",
      "But the user already has the title in quotes. The assistant's job is to rewrite the query to maximize retrieval quality. So the original user query is: \"What is the main contribution of the 'A Survey of LLM-Driven AI Agent Communication' paper?\"\n",
      "\n",
      "The assistant should rephrase it to be more precise without adding information. For example, remove the quotes and make it a standard academic query.\n",
      "\n",
      "But in the previous interaction, the assistant rephrased to \"What is the main contribution of the paper on AI agent communication?\" by changing \"the AI agent communication paper\" to \"the paper on AI agent communication\". Now, the user has a specific title, so the query should be: \"What is the main contribution of the paper titled 'A Survey of LLM-Driven AI Agent Communication'?\"\n",
      "\n",
      "However, the tool might not have that exact paper. But the assistant's role is to call the tool with the best query.\n",
      "\n",
      "Wait, the problem says: \"For each function call, return a json object with function name and arguments within tool_call XML tags\".\n",
      "\n",
      "So the assistant should output a tool_call with the function name and arguments. The arguments should be a JSON object with the query.\n",
      "\n",
      "The user's query is: \"What is the main contribution of the 'A Survey of LLM-Driven AI Agent Communication' paper?\"\n",
      "\n",
      "To maximize retrieval quality, the assistant should rephrase it to be more specific. For example, remove the quotes and make it a standard academic query. But the title is specific, so the best is to use the title as given.\n",
      "\n",
      "Alternatively, the assistant might check if the title exists. But the tool is for retrieval, so the query should be as precise as possible.\n",
      "\n",
      "In the previous example, the assistant rephrased to \"What is the main contribution of the paper on AI agent communication?\" to remove vagueness. Now, the user has a specific title, so the query should be: \"What is the main contribution of the paper titled 'A Survey of LLM-Driven AI Agent Communication'?\"\n",
      "\n",
      "But the quotes might be unnecessary. In academic contexts, titles are often written without quotes in queries.\n",
      "\n",
      "So the improved query could be: \"What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\"\n",
      "\n",
      "But the user used single quotes. The assistant should remove the quotes to make it a standard query.\n",
      "\n",
      "Wait, the problem says: \"do not add new information\". So the assistant shouldn't add or remove information beyond what's necessary for clarity.\n",
      "\n",
      "The original query has the title in quotes. The assistant can remove the quotes and make it a standard title.\n",
      "\n",
      "So the rewritten query is: \"What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\"\n",
      "\n",
      "But the user might have meant the title as a specific string. Alternatively, the assistant could use the title without quotes.\n",
      "\n",
      "In the tool response from earlier, the paper [318] is titled \"A survey of ai agent protocols\". So the user's title has \"LLM-Driven\" which is a newer aspect.\n",
      "\n",
      "Given that, the assistant should call the tool with the query as the user provided, but rephrased to be more precise.\n",
      "\n",
      "Wait, the problem says: \"rewrite it to maximize retrieval quality while preserving intent\". So the assistant should generate a query that's specific and unambiguous.\n",
      "\n",
      "The user's query is a bit long, but the key is the title. The main contribution is what the paper adds. So the query should be: \"What is the main contribution of the paper 'A Survey of LLM-Driven AI Agent Communication'?\"\n",
      "\n",
      "But in the tool call, the query is a string. The assistant should output the tool call with the query string.\n",
      "\n",
      "In the previous interaction, the assistant rephrased to \"What is the main contribution of the paper on AI agent communication?\".\n",
      "\n",
      "Now, the user has a specific title, so the query should be: \"What is the main contribution of the paper titled 'A Survey of LLM-Driven AI Agent Communication'?\"\n",
      "\n",
      "But to remove quotes (as they are not necessary in the query string), it's better to write without quotes.\n",
      "\n",
      "So the query string would be: \"What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\"\n",
      "\n",
      "But the user used single quotes. The assistant can choose to use double quotes in the string or not. However, in JSON, the string should be properly escaped.\n",
      "\n",
      "But the problem says: the arguments should be a JSON object with the query as a string.\n",
      "\n",
      "So the tool call would be:\n",
      "\n",
      "{\n",
      "  \"name\": \"arxiv_paper_retriever\",\n",
      "  \"arguments\": {\n",
      "    \"query\": \"What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\"\n",
      "  }\n",
      "}\n",
      "\n",
      "But wait, the user's original query has the title in quotes. The assistant's rewrite should preserve the intent. The title is a specific string, so the query should include it exactly.\n",
      "\n",
      "Alternatively, the assistant might realize that the paper title might not exist, but the tool will handle it.\n",
      "\n",
      "Given the instructions, the assistant should output the tool call with the query string rephrased to be more precise.\n",
      "\n",
      "In the previous example, the assistant rephrased to \"paper on AI agent communication\" instead of \"AI agent communication paper\". Now, the user has a specific title, so the query should be about that title.\n",
      "\n",
      "So the final tool call is to use the query as: \"What is the main contribution of the paper titled 'A Survey of LLM-Driven AI Agent Communication'?\"\n",
      "\n",
      "But in the tool call JSON, the string should be a valid JSON string. So the quotes inside the string should be escaped or use single quotes.\n",
      "\n",
      "Wait, the problem says: \"return a json object with function name and arguments within tool_call XML tags\".\n",
      "\n",
      "The arguments are a JSON object with a \"query\" string.\n",
      "\n",
      "So the query string can be: \"What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\"\n",
      "\n",
      "But the user used single quotes around the title. To be precise, the assistant should use the title as given, but without quotes in the query string (since quotes in the query string are handled by the JSON).\n",
      "\n",
      "Alternatively, the assistant can write the query string with the title in quotes as a string.\n",
      "\n",
      "But in JSON, the string value can have quotes inside if escaped.\n",
      "\n",
      "For example: \"What is the main contribution of the paper titled \\\"A Survey of LLM-Driven AI Agent Communication\\\"?\"\n",
      "\n",
      "But the problem says: \"do not add new information\". So the assistant shouldn't add quotes around the title in the query string.\n",
      "\n",
      "Wait, the user's query has the title in quotes. The assistant's job is to rewrite the query to maximize retrieval quality. So the best is to remove the quotes and make it a standard academic query.\n",
      "\n",
      "So the query string becomes: \"What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\"\n",
      "\n",
      "This is a single, self-contained question, specific, and unambiguous.\n",
      "\n",
      "Therefore, the tool call is:\n",
      "\n",
      "{\"name\": \"arxiv_paper_retriever\", \"arguments\": {\"query\": \"What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\"}}\n",
      "\n",
      "But wait, the previous tool response shows that there's a paper by Yang et al. (arXiv:2504.16736) titled \"A survey of ai agent protocols\". The user's title has \"LLM-Driven\", which might be a different paper. However, the assistant should still call the tool with the query as given.\n",
      "\n",
      "So the answer is to output the tool call with that query string.\n",
      "</think>\n",
      "Tool Calls:\n",
      "  arxiv_paper_retriever (74beda61-baee-4cdd-9a22-65556103d99d)\n",
      " Call ID: 74beda61-baee-4cdd-9a22-65556103d99d\n",
      "  Args:\n",
      "    query: What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv_paper_retriever\n",
      "\n",
      "A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures\n",
      "Index Terms -large language model, agent communication, attack, and security\n",
      "\n",
      "A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures\n",
      "Dezhang Kong, Shi Lin, Zhenhua Xu, Zhebo Wang, Minghao Li, Yufeng Li, Yilun Zhang, Hujin Peng, Zeyang Sha, Yuyuan Li, Changting Lin, Xun Wang, Xuan Liu, Ningyu Zhang, Chaochao Chen, Muhammad Khurram Khan, Meng Han\n",
      "\n",
      "A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures\n",
      "Abstract -In recent years, Large-Language-Model-driven AI agents have exhibited unprecedented intelligence and adaptability, and are rapidly changing human production and life. Nowadays, agents are undergoing a new round of evolution. They no longer act as an isolated island like LLMs. Instead, they start to communicate with diverse external entities, such as other agents and tools, to perform more complex tasks collectively. Under this trend, agent communication is regarded as a foundational pillar of the future AI ecosystem, and many organizations have intensively begun\n",
      "\n",
      "REFERENCES\n",
      "- [317] Bingyu Yan, Xiaoming Zhang, Litian Zhang, Lian Zhang, Ziyi Zhou, Dezhuang Miao, and Chaozhuo Li. Beyond self-talk: A communication-centric survey of llm-based multi-agent systems. arXiv preprint arXiv:2502.14321 , 2025.\n",
      "\n",
      "B. LLM-Driven AI Agents\n",
      "By integrating the above modules, agents establish a closedloop system that achieves a full chain of perception-decisionaction-feedback . As a result, agents achieve unprecedented ability in automatically finishing domain-specific tasks, being closer to the ultimate form of AI that human expects.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking about the main contribution of an AI agent communication paper. Looking at the retrieved context, I see the paper title is \"A Survey of LLM-Driven AI Agent Communication\" by multiple authors. The abstract mentions that LLM-driven AI agents are evolving to communicate with external entities, and this communication is a foundational pillar for future AI ecosystems. The paper specifically surveys protocols, security risks, and defense countermeasures.\n",
      "\n",
      "The main contribution appears to be a comprehensive survey that identifies key communication protocols, analyzes security risks in LLM-driven agent systems, and proposes defense countermeasures. This addresses the rapid evolution of agents moving beyond isolated operation to collaborative tasks.\n",
      "\n",
      "I need to keep it concise (max 3 sentences) and directly answer. The user's original question was a bit vague about which paper, but the context clearly points to this specific survey paper. I'll focus on the core contribution without extra fluff.\n",
      "</think>\n",
      "\n",
      "The main contribution of the paper is a comprehensive survey of LLM-driven AI agent communication protocols, security risks, and defense countermeasures, addressing how agents evolve from isolated systems to collaborative frameworks with external entities.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"thread_1\"}}\n",
    "\n",
    "input_message = (\n",
    "    \"What is the main contribution of the 'A Survey of LLM-Driven AI Agent Communication' paper?\"\n",
    ")\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": input_message,\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa9a397f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who's the main author?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking \"Who's the main author?\" after a previous interaction where I provided the main contribution of a specific paper. Let me check the context.\n",
      "\n",
      "In the last tool response, the paper title was \"A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures\" with authors listed as Dezhang Kong, Shi Lin, Zhenhua Xu, Zhebo Wang, Minghao Li, Yufeng Li, Yilun Zhang, Hujin Peng, Zeyang Sha, Yuyuan Li, Changting Lin, Xun Wang, Xuan Liu, Ningyu Zhang, Chaochao Chen, Muhammad Khurram Khan, Meng Han.\n",
      "\n",
      "The user wants to know the main author. In academic papers, especially surveys, the main author is often the first author. The list shows Dezhang Kong as the first author. However, sometimes the main author might be determined by the contribution, but without more context, the standard practice is to take the first author as the main author.\n",
      "\n",
      "I should check if there's any indication in the tool response that the main author is different. The tool response lists the authors in order, so the first one is Dezhang Kong. The user might be expecting the first author as the main author.\n",
      "\n",
      "Wait, the previous answer I gave was about the main contribution, and now the user is asking for the main author. So I need to extract the main author from the provided information.\n",
      "\n",
      "The tool response shows the authors in a list starting with Dezhang Kong. So the main author is Dezhang Kong.\n",
      "\n",
      "I should present this clearly. The answer is Dezhang Kong.\n",
      "</think>\n",
      "\n",
      "Dezhang Kong\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Who's the main author?\"\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": input_message,\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f458934",
   "metadata": {},
   "source": [
    "## Inspecting the chat history\n",
    "\n",
    "We can check the stored conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3a60ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the main contribution of the AI agent communication paper?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking about the main contribution of the AI agent communication paper. Hmm, first I need to figure out which specific paper they're referring to. The term \"AI agent communication\" is pretty broad. There are several papers on this topic, like maybe the one from the AI Safety Institute or something else.\n",
      "\n",
      "Wait, the tool provided is arxiv_paper_retriever, which takes a query. So I should use that to look up the most relevant paper. The user probably means a recent paper, maybe the one that's popular or has significant contributions. Let me think, there's a paper titled \"AI Agent Communication\" on arXiv, but I'm not sure. Alternatively, maybe it's a specific paper from a conference.\n",
      "\n",
      "Since the user didn't specify the title, I need to craft a query that will retrieve the main paper in this area. The query could be \"main contribution of AI agent communication paper\" or \"key contributions in AI agent communication\". But the arxiv_paper_retriever function takes a query to look up. Let me check the function description again: it retrieves and answers the question about the arxiv paper. So the query should be something like \"What is the main contribution of the AI agent communication paper?\".\n",
      "\n",
      "Wait, but the function might need a specific paper title. Maybe the user is referring to a well-known paper. For example, there's a paper called \"Communication for AI Agents\" by some authors. Alternatively, maybe the user is thinking of the paper from the 2 as part of the AI community.\n",
      "\n",
      "Alternatively, perhaps the most recent paper on AI agent communication. Let me try to structure the query. The function's query parameter is a string. So I'll use the query: \"main contribution of AI agent communication paper\" to get the answer.\n",
      "\n",
      "Wait, but the function is supposed to retrieve and answer the question. So the tool call would be to arxiv_paper_retriever with the query as the user's question. Let me make sure. The user is asking for the main contribution, so the query should be phrased to get that information.\n",
      "\n",
      "So the tool call would be: name \"arxiv_paper_retriever\", arguments {\"query\": \"What is the main contribution of the AI agent communication paper?\"}\n",
      "\n",
      "But maybe the system expects a more specific query. Alternatively, maybe the paper they're referring to is the one titled \"AI Agents: Communication and Coordination\" or something. But without more context, the best approach is to use the user's exact question as the query.\n",
      "\n",
      "Wait, the user says \"the AI agent communication paper\" which is a bit vague. But the tool is designed to handle such queries. So I'll proceed to call the function with the query as the user's question.\n",
      "</think>\n",
      "Tool Calls:\n",
      "  arxiv_paper_retriever (b8143247-3ecd-453a-b2a2-8cfb6c32a90a)\n",
      " Call ID: b8143247-3ecd-453a-b2a2-8cfb6c32a90a\n",
      "  Args:\n",
      "    query: What is the main contribution of the AI agent communication paper?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv_paper_retriever\n",
      "\n",
      "I. INTRODUCTION\n",
      "[89], which enables seamless communication and collaboration among agents. Since its release, A2A has received extensive support from many enterprises, such as Microsoft [200], Atlassian [160], and PayPal [242]. It can be seen that the breakthroughs in agent communication are bringing rapid and profound changes and will become an indispensable part of the AI ecosystem.\n",
      "\n",
      "E. Takeaways\n",
      "their capability of executing tools. As a result, studying the security of agent communication is significant to the AI ecosystem.\n",
      "\n",
      "REFERENCES\n",
      "[204] Erik Miehling, Karthikeyan Natesan Ramamurthy, Kush R Varshney, Matthew Riemer, Djallel Bouneffouf, John T Richards, Amit Dhurandhar, Elizabeth M Daly, Michael Hind, Prasanna Sattigeri, et al. Agentic ai needs a systems theory. arXiv preprint arXiv:2503.00237 , 2025.\n",
      "\n",
      "REFERENCES\n",
      "- [318] Yingxuan Yang, Huacan Chai, Yuanyi Song, Siyuan Qi, Muning Wen, Ning Li, Junwei Liao, Haoyi Hu, Jianghao Lin, Gaowei Chang, et al. A survey of ai agent protocols. arXiv preprint arXiv:2504.16736 , 2025.\n",
      "\n",
      "I. INTRODUCTION\n",
      "Now, agents are evolving towards the direction of domainspecific entities, i.e., being customized for specific scenarios and tasks. In this context, as shown in Figure 1, a task usually requires the collaboration of multiple agents, which may be located globally on the Internet. Under this condition, agent communication becomes the foundation of the future AI ecosystem. It enables agents to find other agents with specific capabilities, access external knowledge, assign tasks, and engage in other interactions. Based on the vast market of agent communication, an increasing number of communities and companies are seizing the opportunity to contribute to the development of agent\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "<think>\n",
      "We are given the original question: \"What is the main contribution of the AI agent communication paper?\"\n",
      "\n",
      "We are to rewrite it to maximize retrieval quality while preserving intent. The guidelines are:\n",
      "- Keep it specific and unambiguous; include essential entities, time ranges, and constraints.\n",
      "- Remove vague words; prefer domain terms from the original question when helpful.\n",
      "- Keep it a single, self-contained question; do not add new information.\n",
      "\n",
      "Analysis of the original question:\n",
      "- The question is asking for the \"main contribution\" of a paper titled \"AI agent communication\".\n",
      "- However, note that the original question does not specify which paper. There are multiple papers on AI agent communication. The term \"the AI agent communication paper\" is vague because it doesn't specify a particular paper.\n",
      "\n",
      "To maximize retrieval quality, we need to make the question more specific. But note: the guidelines say not to add new information. So we cannot invent a paper title or author.\n",
      "\n",
      "But wait: the original question says \"the AI agent communication paper\". This implies that the user might be referring to a specific well-known paper? However, in the context of retrieval, we don't know which one. \n",
      "\n",
      "In the real world, there is a famous paper: \"AI Agent Communication: A Survey\" by some authors? But actually, the most prominent paper in this area might be the one from the conference \"AAAI\" or \"NeurIPS\" etc. However, without more context, we cannot assume.\n",
      "\n",
      "But note: the instruction says \"preserve intent\". The intent is to find the main contribution of a paper that is about AI agent communication. However, the user says \"the paper\", implying a specific one. But without a title or author, we have to be careful.\n",
      "\n",
      "Alternative approach: In the context of academic retrieval, if the user is referring to a specific paper that is well-known, we might have to leave it as is? But the problem says to remove vague words.\n",
      "\n",
      "Let's think: the term \"AI agent communication\" is a bit vague. There are multiple papers. However, the user might be referring to a particular paper that they have in mind? But we don't have that context.\n",
      "\n",
      "Given the constraints, we can try to rephrase to be more specific without adding information. But note: the original question does not specify a paper. So we have to make it clear that we are talking about a specific paper? Actually, the problem says: \"include essential entities, time ranges, and constraints\". \n",
      "\n",
      "But the user didn't provide any. So we have to work with what we have.\n",
      "\n",
      "Idea: The most common paper that comes to mind in this area is the one by the group at the University of California, Berkeley? Or perhaps the paper \"A Survey of AI Agent Communication\" by [author]? But we don't know.\n",
      "\n",
      "Alternatively, we can rephrase to be more precise about the domain. However, the guidelines say: remove vague words. The word \"main\" is a bit vague? But in academic context, \"main contribution\" is standard.\n",
      "\n",
      "Another idea: The user might have meant a specific paper that is well-known in the field. For example, the paper \"Communication in Multi-Agent Systems\" by [author]? But again, we don't know.\n",
      "\n",
      "Given the instructions, we are to rewrite the question without adding new information. So we cannot assume a specific paper.\n",
      "\n",
      "But note: the original question says \"the AI agent communication paper\". This is a bit odd because there isn't one single paper. So the best we can do is to make it clear that we are looking for the main contribution of a paper that is about AI agent communication, but without specifying which one? However, that would be too vague.\n",
      "\n",
      "Wait, the problem says: \"maximize retrieval quality\". In retrieval systems, if we don't specify the paper, the system might return multiple papers. But the user wants the main contribution of \"the\" paper, implying one.\n",
      "\n",
      "How about we rephrase to: \"What is the main contribution of the seminal paper on AI agent communication?\"\n",
      "\n",
      "But note: the guideline says \"do not add new information\". The word \"seminal\" is new? And we don't know if there is a seminal paper. Also, the original question didn't say \"seminal\".\n",
      "\n",
      "Alternatively, we can try to use the term \"the\" as a reference to a specific paper that is well-known? But without context, it's risky.\n",
      "\n",
      "Let me check: In the field of AI, there is a paper called \"AI Agent Communication: A Survey\" by [author]? Actually, I recall that there is a paper by the group at the University of California, Berkeley: \"A Survey of AI Agent Communication\" (but I'm not sure of the exact title).\n",
      "\n",
      "However, the problem says: do not add new information. So we cannot assume a title.\n",
      "\n",
      "Another approach: The user might have meant the paper that is the most recent? But again, we don't know.\n",
      "\n",
      "Given the constraints, I think the best we can do is to rephrase to be more precise about the topic without adding new information. But the original question is already a bit vague.\n",
      "\n",
      "Wait, the problem says: \"include essential entities\". The essential entity here is the topic: \"AI agent communication\". But we don't have a specific paper.\n",
      "\n",
      "I think the key is to realize that the user might have intended a specific paper that is well-known in the field. However, without knowing which one, we have to leave it as a general question? But that doesn't maximize retrieval.\n",
      "\n",
      "Alternatively, we can rephrase to: \"What is the main contribution of the paper on AI agent communication?\"\n",
      "\n",
      "But that's almost the same.\n",
      "\n",
      "Let me look for common practices in academic retrieval. In many contexts, when someone says \"the paper on X\", they mean a specific one. But without context, we can't.\n",
      "\n",
      "Given the instructions, I think we have to make the question as specific as possible without adding information. So we can try to use the term \"AI agent communication\" as the topic and remove the vague word \"the\" (which implies a specific one) but that might not help.\n",
      "\n",
      "Wait, the original question says \"the AI agent communication paper\". The phrase \"AI agent communication paper\" is a bit of a compound noun. We can break it down.\n",
      "\n",
      "I propose: \"What is the main contribution of the paper titled 'AI Agent Communication'?\"\n",
      "\n",
      "But note: the original question doesn't have a title. And we don't know if there is a paper with that exact title. Also, the guideline says: do not add new information. We are adding the word \"titled\" and the quotes? That might be considered adding.\n",
      "\n",
      "Alternatively, we can write: \"What is the main contribution of the AI agent communication paper?\"\n",
      "\n",
      "But that's the same as the original.\n",
      "\n",
      "Wait, the problem says: \"remove vague words\". The word \"the\" might be vague? But in English, \"the\" is used to specify a particular paper. However, without context, it's vague.\n",
      "\n",
      "Another idea: In the field of AI, there is a well-known paper: \"A Survey of AI Agent Communication\" by [author]? But we don't have the author.\n",
      "\n",
      "I think the best course of action is to rephrase to be more precise about the domain without adding new information. But the original question is already specific enough? \n",
      "\n",
      "Wait, the problem says: \"maximize retrieval quality\". So we want the question to be as specific as possible without adding information. \n",
      "\n",
      "Let me try to think of what a retrieval system would need. The system might require:\n",
      "- The topic: AI agent communication\n",
      "- The type of paper: but the user says \"paper\", so we don't need to specify.\n",
      "\n",
      "But the user says \"the paper\", which implies one. However, without a title or author, the system might return multiple.\n",
      "\n",
      "Given the constraints, I think we can rewrite the question to be: \"What is the main contribution of the AI agent communication paper?\"\n",
      "\n",
      "But that's the same as the original. However, the problem says to rewrite to maximize retrieval quality. So we have to make it more specific.\n",
      "\n",
      "Wait, the problem says: \"include essential entities\". The essential entity here is the topic: \"AI agent communication\". But we don't have a specific paper.\n",
      "\n",
      "I found a paper: \"AI Agent Communication: A Survey\" by [author] is not a single paper. There are many.\n",
      "\n",
      "Another thought: The user might be referring to the paper that is the most recent in the field? But we don't know.\n",
      "\n",
      "Given the instructions, I think we have to accept that the question is inherently vague and we can only make it more precise by removing the vague word \"the\". But that doesn't help.\n",
      "\n",
      "Alternatively, we can rephrase to: \"What is the main contribution of a paper on AI agent communication?\"\n",
      "\n",
      "But that's still vague.\n",
      "\n",
      "Wait, the problem says: \"prefer domain terms from the original question\". The original question uses \"AI agent communication\", which is a domain term.\n",
      "\n",
      "I think the best we can do is to write the question as: \"What is the main contribution of the AI agent communication paper?\"\n",
      "\n",
      "But that's the same as the original. However, the problem says to rewrite. So we have to change it a bit.\n",
      "\n",
      "Let me try: \"What is the primary contribution of the seminal AI agent communication paper?\"\n",
      "\n",
      "But we added \"seminal\" and \"primary\" (which is a synonym for main) and we don't know if it's seminal.\n",
      "\n",
      "The guideline says: do not add new information. So we cannot add \"seminal\".\n",
      "\n",
      "Another idea: In the context of the field, there is a paper that is often referred to as the foundational one? But again, we don't know.\n",
      "\n",
      "I think the answer is that we cannot make it more specific without adding information. But the problem says to rewrite.\n",
      "\n",
      "Wait, the problem says: \"maximize retrieval quality\". So we want the question to be as specific as possible without adding information. \n",
      "\n",
      "I recall that in academic search, if you want to find a specific paper, you need to have the title or authors. But the user didn't provide that.\n",
      "\n",
      "Given the constraints, I will rewrite the question to be: \"What is the main contribution of the paper on AI agent communication?\"\n",
      "\n",
      "This removes the vague \"the\" (which implies a specific one) and makes it \"paper on AI agent communication\" which is a bit more standard in academic contexts? But the original had \"the AI agent communication paper\", which is a bit awkward.\n",
      "\n",
      "Alternatively, we can write: \"What is the main contribution of AI agent communication papers?\"\n",
      "\n",
      "But that would be plural and the user said \"paper\" (singular).\n",
      "\n",
      "After careful thought, I think the best rewrite is: \"What is the main contribution of the AI agent communication paper?\"\n",
      "\n",
      "But that's the same. \n",
      "\n",
      "Wait, the problem says: \"remove vague words\". The word \"the\" might be considered vague? But in English, it's not vague. \n",
      "\n",
      "Another approach: The user might have meant a specific paper that is well-known in the field. For example, the paper \"A Survey of AI Agent Communication\" by [author] is not a single paper. \n",
      "\n",
      "I found that there is a paper: \"AI Agent Communication: A Survey\" by [author] but I don't know the exact title.\n",
      "\n",
      "Given the time, I will go with a rewrite that is more precise by using the term \"paper\" without the article? But that's not standard.\n",
      "\n",
      "Let me look for a standard way. In academic contexts, we often say: \"What is the main contribution of the paper on AI agent communication?\"\n",
      "\n",
      "But the original had \"the AI agent communication paper\", which is a bit of a compound noun.\n",
      "\n",
      "I think the improved question should be: \"What is the main contribution of the paper on AI agent communication?\"\n",
      "\n",
      "This removes the vagueness of \"the\" (which might be interpreted as a specific one) by making it \"the paper on AI agent communication\", which is a common way to phrase it in academic retrieval.\n",
      "\n",
      "But note: the original question says \"the AI agent communication paper\", which is a noun phrase. We are changing it to \"the paper on AI agent communication\", which is a bit more natural.\n",
      "\n",
      "However, the guideline says: do not add new information. We are not adding new information, just rephrasing.\n",
      "\n",
      "Let me compare:\n",
      "Original: \"What is the main contribution of the AI agent communication paper?\"\n",
      "Rewrite: \"What is the main contribution of the paper on AI agent communication?\"\n",
      "\n",
      "This is a common rephrasing in English to be more precise. Also, it removes the potential ambiguity of the phrase \"AI agent communication paper\" (which might be misinterpreted as a type of paper or a specific paper).\n",
      "\n",
      "But note: the original question uses \"AI agent communication\" as a compound adjective. In the rewrite, we use \"on AI agent communication\" as a prepositional phrase.\n",
      "\n",
      "This rewrite is more specific because it clarifies that we are talking about a paper that deals with AI agent communication (as a topic), rather than a paper that is called \"AI agent communication\" (which might not exist).\n",
      "\n",
      "Also, it's a single, self-contained question.\n",
      "\n",
      "So I think this is a good rewrite.\n",
      "\n",
      "Let's check the guidelines:\n",
      "- Specific and unambiguous: Yes, because it's clear that we are talking about a paper that covers the topic of AI agent communication.\n",
      "- Remove vague words: The word \"the\" is still there, but it's necessary. We removed the compound adjective structure which was a bit vague. The phrase \"paper on AI agent communication\" is a standard way to say it.\n",
      "- Prefer domain terms: We used \"AI agent communication\" which is a domain term from the original.\n",
      "- Single, self-contained question: Yes.\n",
      "\n",
      "Therefore, the improved question is: \"What is the main contribution of the paper on AI agent communication?\"\n",
      "\n",
      "But wait, the original question says \"the AI agent communication paper\", which might be intended to be a specific paper. However, in the context of retrieval, this rewrite is more likely to return the intended paper (if there is one) or a set of papers on that topic, but the user said \"the paper\", so they might be thinking of a specific one. \n",
      "\n",
      "Given the constraints, this is the best we can do.\n",
      "\n",
      "Alternatively, if we want to be even more specific, we could add a time range? But the user didn't provide one.\n",
      "\n",
      "So I'll go with that.\n",
      "\n",
      "Final improved question: \"What is the main contribution of the paper on AI agent communication?\"\n",
      "\n",
      "But note: the problem says \"do not add new information\". We didn't add any new information, just rephrased.\n",
      "\n",
      "Let me write it as a string.\n",
      "\n",
      "Improved question: \"What is the main contribution of the paper on AI agent communication?\"\n",
      "\n",
      "However, in the field, sometimes the term \"AI agent communication\" is written with a hyphen: \"AI agent communication\" (with space) or \"AI-agent communication\"? But the original used \"AI agent communication\", so we keep it.\n",
      "\n",
      "Another note: The original question has \"AI agent communication\" (with space) so we keep the space.\n",
      "\n",
      "So the answer is: \"What is the main contribution of the paper on AI agent communication?\"\n",
      "\n",
      "But wait, the problem says: \"include essential entities, time ranges, and constraints\". We have the essential entity: \"AI agent communication\". Time ranges and constraints are not provided in the original, so we don't add any.\n",
      "\n",
      "Therefore, I think this is the improved question.\n",
      "</think>\n",
      "\n",
      "What is the main contribution of the paper on AI agent communication?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, let me break this down. The user asked: \"What is the main contribution of the AI agent communication paper?\"\n",
      "\n",
      "First, I need to check if there's a specific paper they're referring to. The term \"the AI agent communication paper\" is vague because there are multiple papers on this topic. In academic contexts, this phrasing usually implies a well-known or seminal paper, but without more details, it's ambiguous.\n",
      "\n",
      "Looking at the tool response provided earlier, it shows references to two papers:\n",
      "1. [204] Erik Miehling et al. \"Agentic ai needs a systems theory\" (2025)\n",
      "2. [318] Yingxuan Yang et al. \"A survey of ai agent protocols\" (2025)\n",
      "\n",
      "The user's question likely refers to one of these, especially since the second paper is a survey on agent protocols. The phrase \"AI agent communication paper\" might be shorthand for a specific survey paper in this field.\n",
      "\n",
      "To maximize retrieval quality, I should make the query more precise without adding new information. The original question uses \"the\" which implies a specific paper, but without context, it's too vague. The improved query should:\n",
      "- Keep the core intent: main contribution of a paper on AI agent communication\n",
      "- Remove vague terms: \"the\" can be kept but the phrasing should clarify it's about a paper *on* the topic (not a paper titled \"AI agent communication\")\n",
      "- Use standard academic phrasing: \"paper on AI agent communication\" is clearer than \"AI agent communication paper\"\n",
      "\n",
      "The rewrite \"What is the main contribution of the paper on AI agent communication?\" is more precise because:\n",
      "- It specifies the paper is *about* the topic (not a paper with that title)\n",
      "- It avoids implying a single paper exists (which is realistic since there are multiple)\n",
      "- It uses domain terms from the original (\"AI agent communication\")\n",
      "- It's a single, self-contained question\n",
      "\n",
      "This rewrite aligns with the guidelines: no new information added, specific enough for retrieval, and preserves the user's intent.\n",
      "\n",
      "So the final tool call uses this improved query.\n",
      "</think>\n",
      "Tool Calls:\n",
      "  arxiv_paper_retriever (66d50957-d661-4622-93a6-638a6220889a)\n",
      " Call ID: 66d50957-d661-4622-93a6-638a6220889a\n",
      "  Args:\n",
      "    query: What is the main contribution of the paper on AI agent communication?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv_paper_retriever\n",
      "\n",
      "I. INTRODUCTION\n",
      "[89], which enables seamless communication and collaboration among agents. Since its release, A2A has received extensive support from many enterprises, such as Microsoft [200], Atlassian [160], and PayPal [242]. It can be seen that the breakthroughs in agent communication are bringing rapid and profound changes and will become an indispensable part of the AI ecosystem.\n",
      "\n",
      "E. Takeaways\n",
      "their capability of executing tools. As a result, studying the security of agent communication is significant to the AI ecosystem.\n",
      "\n",
      "REFERENCES\n",
      "- [318] Yingxuan Yang, Huacan Chai, Yuanyi Song, Siyuan Qi, Muning Wen, Ning Li, Junwei Liao, Haoyi Hu, Jianghao Lin, Gaowei Chang, et al. A survey of ai agent protocols. arXiv preprint arXiv:2504.16736 , 2025.\n",
      "\n",
      "REFERENCES\n",
      "[204] Erik Miehling, Karthikeyan Natesan Ramamurthy, Kush R Varshney, Matthew Riemer, Djallel Bouneffouf, John T Richards, Amit Dhurandhar, Elizabeth M Daly, Michael Hind, Prasanna Sattigeri, et al. Agentic ai needs a systems theory. arXiv preprint arXiv:2503.00237 , 2025.\n",
      "\n",
      "TABLE I\n",
      "- This survey exhibits a comprehensive illustration of the existing protocols related to different agent communication stages (Sections V-A, VI-A, and VII-A), including newly proposed and previously neglected protocols that have not been discussed by other surveys. Besides, we categorize these protocols based on their architecture and summarize corresponding characteristics, rather than mechanically listing each protocol. This organization method can allow any researchers interested in this field to quickly establish a preliminary but comprehensive understanding of agent communication.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the main contribution of the 'A Survey of LLM-Driven AI Agent Communication' paper?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, let me try to figure out how to approach this. The user is asking about the main contribution of a specific paper titled \"A Survey of LLM-Driven AI Agent Communication\". \n",
      "\n",
      "First, I need to check if there's a paper with that exact title in the arXiv database. The user mentioned it's a survey paper, so it's likely a recent one. But in the previous interactions, the assistant used the arxiv_paper_retriever function to get information about AI agent communication papers. The tool response from earlier shows references to papers like [318] by Yingxuan Yang et al. (arXiv:2504.16736) titled \"A survey of ai agent protocols\" and [204] by Erik Miehling et al. (arXiv:2503.00237) titled \"Agentic ai needs a systems theory\".\n",
      "\n",
      "Wait, the user's current question is about \"A Survey of LLM-Driven AI Agent Communication\". The previous tool response mentions a paper by Yang et al. that's a survey of AI agent protocols (arXiv:2504.16736). But the user's title has \"LLM-Driven\" which might be a newer paper. However, the arXiv preprint from Yang et al. (2025) is a survey of AI agent protocols, not specifically LLM-driven.\n",
      "\n",
      "Hmm, the user might be conflating the title. The previous tool response shows that the paper [318] is titled \"A survey of ai agent protocols\" (arXiv:2504.16736). The user's question has \"LLM-Driven\" which isn't in the title of that paper. So maybe the user is referring to a different paper, but the tool response doesn't have a paper with \"LLM-Driven\" in the title.\n",
      "\n",
      "Wait, the problem says that the assistant can call the arxiv_paper_retriever function. The user is asking for the main contribution of that specific paper. But the tool response from the previous call shows that the paper [318] is a survey of AI agent protocols. The user's title has \"LLM-Driven\", which might be a mistake or a different paper.\n",
      "\n",
      "I need to check if there's a paper with that exact title. But since the tool response from the previous call doesn't include it, maybe the user is referring to the Yang et al. paper but with a slightly different title. Alternatively, the \"LLM-Driven\" part might be a recent addition.\n",
      "\n",
      "The assistant's job is to call the arxiv_paper_retriever with the query. The user's query is: \"What is the main contribution of the 'A Survey of LLM-Driven AI Agent Communication' paper?\"\n",
      "\n",
      "So the correct tool call would be to use the arxiv_paper_retriever with that query. But the previous tool response shows that the paper [318] is a survey of AI agent protocols (without LLM-Driven). So maybe the user's title is slightly off, but the assistant should still use the query as given.\n",
      "\n",
      "Wait, the problem says: \"You may call one or more functions to assist with the user query.\" So the assistant should generate a tool call for the arxiv_paper_retriever with the user's query.\n",
      "\n",
      "The user's query is: \"What is the main contribution of the 'A Survey of LLM-Driven AI Agent Communication' paper?\"\n",
      "\n",
      "So the tool call should be:\n",
      "\n",
      "{\n",
      "  \"name\": \"arxiv_paper_retriever\",\n",
      "  \"arguments\": {\n",
      "    \"query\": \"What is the main contribution of the 'A Survey of LLM-Driven AI Agent Communication' paper?\"\n",
      "  }\n",
      "}\n",
      "\n",
      "But in the previous interactions, the assistant used the tool with a slightly rephrased query. However, the user now specified the exact title with quotes. The assistant should use the query as the user provided it, but maybe adjust to be more precise without adding info.\n",
      "\n",
      "Wait, the guidelines say: \"rewrite it to maximize retrieval quality while preserving intent\". So the assistant should rephrase the query to be more specific and unambiguous.\n",
      "\n",
      "The user's query has a title in quotes: 'A Survey of LLM-Driven AI Agent Communication'. The problem is that the title might not exist exactly, but the assistant should try to make the query as specific as possible.\n",
      "\n",
      "In the previous example, the assistant rephrased to \"What is the main contribution of the paper on AI agent communication?\" to remove vagueness. Now, the user has a specific title, so the query should be more precise.\n",
      "\n",
      "But the user's title includes \"LLM-Driven\", which is a specific term. So the best rewrite would be to use the exact title as given, but maybe remove the quotes and make it a standard query.\n",
      "\n",
      "Wait, the problem says: \"include essential entities, time ranges, and constraints\". The essential entity here is the paper title. So the query should be: \"What is the main contribution of the paper titled 'A Survey of LLM-Driven AI Agent Communication'?\"\n",
      "\n",
      "But the user already has the title in quotes. The assistant's job is to rewrite the query to maximize retrieval quality. So the original user query is: \"What is the main contribution of the 'A Survey of LLM-Driven AI Agent Communication' paper?\"\n",
      "\n",
      "The assistant should rephrase it to be more precise without adding information. For example, remove the quotes and make it a standard academic query.\n",
      "\n",
      "But in the previous interaction, the assistant rephrased to \"What is the main contribution of the paper on AI agent communication?\" by changing \"the AI agent communication paper\" to \"the paper on AI agent communication\". Now, the user has a specific title, so the query should be: \"What is the main contribution of the paper titled 'A Survey of LLM-Driven AI Agent Communication'?\"\n",
      "\n",
      "However, the tool might not have that exact paper. But the assistant's role is to call the tool with the best query.\n",
      "\n",
      "Wait, the problem says: \"For each function call, return a json object with function name and arguments within tool_call XML tags\".\n",
      "\n",
      "So the assistant should output a tool_call with the function name and arguments. The arguments should be a JSON object with the query.\n",
      "\n",
      "The user's query is: \"What is the main contribution of the 'A Survey of LLM-Driven AI Agent Communication' paper?\"\n",
      "\n",
      "To maximize retrieval quality, the assistant should rephrase it to be more specific. For example, remove the quotes and make it a standard academic query. But the title is specific, so the best is to use the title as given.\n",
      "\n",
      "Alternatively, the assistant might check if the title exists. But the tool is for retrieval, so the query should be as precise as possible.\n",
      "\n",
      "In the previous example, the assistant rephrased to \"What is the main contribution of the paper on AI agent communication?\" to remove vagueness. Now, the user has a specific title, so the query should be: \"What is the main contribution of the paper titled 'A Survey of LLM-Driven AI Agent Communication'?\"\n",
      "\n",
      "But the quotes might be unnecessary. In academic contexts, titles are often written without quotes in queries.\n",
      "\n",
      "So the improved query could be: \"What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\"\n",
      "\n",
      "But the user used single quotes. The assistant should remove the quotes to make it a standard query.\n",
      "\n",
      "Wait, the problem says: \"do not add new information\". So the assistant shouldn't add or remove information beyond what's necessary for clarity.\n",
      "\n",
      "The original query has the title in quotes. The assistant can remove the quotes and make it a standard title.\n",
      "\n",
      "So the rewritten query is: \"What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\"\n",
      "\n",
      "But the user might have meant the title as a specific string. Alternatively, the assistant could use the title without quotes.\n",
      "\n",
      "In the tool response from earlier, the paper [318] is titled \"A survey of ai agent protocols\". So the user's title has \"LLM-Driven\" which is a newer aspect.\n",
      "\n",
      "Given that, the assistant should call the tool with the query as the user provided, but rephrased to be more precise.\n",
      "\n",
      "Wait, the problem says: \"rewrite it to maximize retrieval quality while preserving intent\". So the assistant should generate a query that's specific and unambiguous.\n",
      "\n",
      "The user's query is a bit long, but the key is the title. The main contribution is what the paper adds. So the query should be: \"What is the main contribution of the paper 'A Survey of LLM-Driven AI Agent Communication'?\"\n",
      "\n",
      "But in the tool call, the query is a string. The assistant should output the tool call with the query string.\n",
      "\n",
      "In the previous interaction, the assistant rephrased to \"What is the main contribution of the paper on AI agent communication?\".\n",
      "\n",
      "Now, the user has a specific title, so the query should be: \"What is the main contribution of the paper titled 'A Survey of LLM-Driven AI Agent Communication'?\"\n",
      "\n",
      "But to remove quotes (as they are not necessary in the query string), it's better to write without quotes.\n",
      "\n",
      "So the query string would be: \"What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\"\n",
      "\n",
      "But the user used single quotes. The assistant can choose to use double quotes in the string or not. However, in JSON, the string should be properly escaped.\n",
      "\n",
      "But the problem says: the arguments should be a JSON object with the query as a string.\n",
      "\n",
      "So the tool call would be:\n",
      "\n",
      "{\n",
      "  \"name\": \"arxiv_paper_retriever\",\n",
      "  \"arguments\": {\n",
      "    \"query\": \"What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\"\n",
      "  }\n",
      "}\n",
      "\n",
      "But wait, the user's original query has the title in quotes. The assistant's rewrite should preserve the intent. The title is a specific string, so the query should include it exactly.\n",
      "\n",
      "Alternatively, the assistant might realize that the paper title might not exist, but the tool will handle it.\n",
      "\n",
      "Given the instructions, the assistant should output the tool call with the query string rephrased to be more precise.\n",
      "\n",
      "In the previous example, the assistant rephrased to \"paper on AI agent communication\" instead of \"AI agent communication paper\". Now, the user has a specific title, so the query should be about that title.\n",
      "\n",
      "So the final tool call is to use the query as: \"What is the main contribution of the paper titled 'A Survey of LLM-Driven AI Agent Communication'?\"\n",
      "\n",
      "But in the tool call JSON, the string should be a valid JSON string. So the quotes inside the string should be escaped or use single quotes.\n",
      "\n",
      "Wait, the problem says: \"return a json object with function name and arguments within tool_call XML tags\".\n",
      "\n",
      "The arguments are a JSON object with a \"query\" string.\n",
      "\n",
      "So the query string can be: \"What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\"\n",
      "\n",
      "But the user used single quotes around the title. To be precise, the assistant should use the title as given, but without quotes in the query string (since quotes in the query string are handled by the JSON).\n",
      "\n",
      "Alternatively, the assistant can write the query string with the title in quotes as a string.\n",
      "\n",
      "But in JSON, the string value can have quotes inside if escaped.\n",
      "\n",
      "For example: \"What is the main contribution of the paper titled \\\"A Survey of LLM-Driven AI Agent Communication\\\"?\"\n",
      "\n",
      "But the problem says: \"do not add new information\". So the assistant shouldn't add quotes around the title in the query string.\n",
      "\n",
      "Wait, the user's query has the title in quotes. The assistant's job is to rewrite the query to maximize retrieval quality. So the best is to remove the quotes and make it a standard academic query.\n",
      "\n",
      "So the query string becomes: \"What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\"\n",
      "\n",
      "This is a single, self-contained question, specific, and unambiguous.\n",
      "\n",
      "Therefore, the tool call is:\n",
      "\n",
      "{\"name\": \"arxiv_paper_retriever\", \"arguments\": {\"query\": \"What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\"}}\n",
      "\n",
      "But wait, the previous tool response shows that there's a paper by Yang et al. (arXiv:2504.16736) titled \"A survey of ai agent protocols\". The user's title has \"LLM-Driven\", which might be a different paper. However, the assistant should still call the tool with the query as given.\n",
      "\n",
      "So the answer is to output the tool call with that query string.\n",
      "</think>\n",
      "Tool Calls:\n",
      "  arxiv_paper_retriever (74beda61-baee-4cdd-9a22-65556103d99d)\n",
      " Call ID: 74beda61-baee-4cdd-9a22-65556103d99d\n",
      "  Args:\n",
      "    query: What is the main contribution of the paper titled A Survey of LLM-Driven AI Agent Communication?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv_paper_retriever\n",
      "\n",
      "A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures\n",
      "Index Terms -large language model, agent communication, attack, and security\n",
      "\n",
      "A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures\n",
      "Dezhang Kong, Shi Lin, Zhenhua Xu, Zhebo Wang, Minghao Li, Yufeng Li, Yilun Zhang, Hujin Peng, Zeyang Sha, Yuyuan Li, Changting Lin, Xun Wang, Xuan Liu, Ningyu Zhang, Chaochao Chen, Muhammad Khurram Khan, Meng Han\n",
      "\n",
      "A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures\n",
      "Abstract -In recent years, Large-Language-Model-driven AI agents have exhibited unprecedented intelligence and adaptability, and are rapidly changing human production and life. Nowadays, agents are undergoing a new round of evolution. They no longer act as an isolated island like LLMs. Instead, they start to communicate with diverse external entities, such as other agents and tools, to perform more complex tasks collectively. Under this trend, agent communication is regarded as a foundational pillar of the future AI ecosystem, and many organizations have intensively begun\n",
      "\n",
      "REFERENCES\n",
      "- [317] Bingyu Yan, Xiaoming Zhang, Litian Zhang, Lian Zhang, Ziyi Zhou, Dezhuang Miao, and Chaozhuo Li. Beyond self-talk: A communication-centric survey of llm-based multi-agent systems. arXiv preprint arXiv:2502.14321 , 2025.\n",
      "\n",
      "B. LLM-Driven AI Agents\n",
      "By integrating the above modules, agents establish a closedloop system that achieves a full chain of perception-decisionaction-feedback . As a result, agents achieve unprecedented ability in automatically finishing domain-specific tasks, being closer to the ultimate form of AI that human expects.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking about the main contribution of an AI agent communication paper. Looking at the retrieved context, I see the paper title is \"A Survey of LLM-Driven AI Agent Communication\" by multiple authors. The abstract mentions that LLM-driven AI agents are evolving to communicate with external entities, and this communication is a foundational pillar for future AI ecosystems. The paper specifically surveys protocols, security risks, and defense countermeasures.\n",
      "\n",
      "The main contribution appears to be a comprehensive survey that identifies key communication protocols, analyzes security risks in LLM-driven agent systems, and proposes defense countermeasures. This addresses the rapid evolution of agents moving beyond isolated operation to collaborative tasks.\n",
      "\n",
      "I need to keep it concise (max 3 sentences) and directly answer. The user's original question was a bit vague about which paper, but the context clearly points to this specific survey paper. I'll focus on the core contribution without extra fluff.\n",
      "</think>\n",
      "\n",
      "The main contribution of the paper is a comprehensive survey of LLM-driven AI agent communication protocols, security risks, and defense countermeasures, addressing how agents evolve from isolated systems to collaborative frameworks with external entities.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who's the main author?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking \"Who's the main author?\" after a previous interaction where I provided the main contribution of a specific paper. Let me check the context.\n",
      "\n",
      "In the last tool response, the paper title was \"A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures\" with authors listed as Dezhang Kong, Shi Lin, Zhenhua Xu, Zhebo Wang, Minghao Li, Yufeng Li, Yilun Zhang, Hujin Peng, Zeyang Sha, Yuyuan Li, Changting Lin, Xun Wang, Xuan Liu, Ningyu Zhang, Chaochao Chen, Muhammad Khurram Khan, Meng Han.\n",
      "\n",
      "The user wants to know the main author. In academic papers, especially surveys, the main author is often the first author. The list shows Dezhang Kong as the first author. However, sometimes the main author might be determined by the contribution, but without more context, the standard practice is to take the first author as the main author.\n",
      "\n",
      "I should check if there's any indication in the tool response that the main author is different. The tool response lists the authors in order, so the first one is Dezhang Kong. The user might be expecting the first author as the main author.\n",
      "\n",
      "Wait, the previous answer I gave was about the main contribution, and now the user is asking for the main author. So I need to extract the main author from the provided information.\n",
      "\n",
      "The tool response shows the authors in a list starting with Dezhang Kong. So the main author is Dezhang Kong.\n",
      "\n",
      "I should present this clearly. The answer is Dezhang Kong.\n",
      "</think>\n",
      "\n",
      "Dezhang Kong\n"
     ]
    }
   ],
   "source": [
    "chat_history = graph.get_state(config).values[\"messages\"]\n",
    "for message in chat_history:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851d3036",
   "metadata": {},
   "source": [
    "# Basic offline evaluation with NDCG@k\n",
    "\n",
    "We check if the chunks' ranking is sufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61059385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gh/wtmb1km14f710f4f7s07wk380000gn/T/ipykernel_88652/657142174.py:44: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5 report: {'k': 5, 'num_queries': 5, 'ndcg@k_mean': 0.35385596211497444, 'per_query': [0.0, 0.0, 0.0, 1.0, 0.7692798105748722]}\n"
     ]
    }
   ],
   "source": [
    "from math import log2\n",
    "from typing import List\n",
    "\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "\n",
    "def dcg(relevances: List[int]) -> float:\n",
    "    \"\"\"\n",
    "    Discounted Cumulative Gain for a ranked list of binary relevances.\n",
    "    rel in {0,1}; rank starts from 1; DCG = sum_{i}(rel_i / log2(i+1)).\n",
    "    \"\"\"\n",
    "    return sum((rel / log2(idx + 2)) for idx, rel in enumerate(relevances))\n",
    "\n",
    "\n",
    "def ndcg_at_k(relevances: List[int], k: int) -> float:\n",
    "    \"\"\"\n",
    "    Compute NDCG@k for a ranked list of binary relevances.\n",
    "    - relevances: list of 0/1 labels in rank order (retriever output order)\n",
    "    - k: cutoff\n",
    "    \"\"\"\n",
    "    r = relevances[:k]\n",
    "    ideal = sorted(r, reverse=True)\n",
    "    return ndcg_score([r], [ideal])\n",
    "\n",
    "\n",
    "def grade_binary(question: str, context: str) -> int:\n",
    "    \"\"\"\n",
    "    Binary relevance using the existing grader LLM (yes->1, no->0).\n",
    "    Reuses GRADE_PROMPT + GradeDocuments for consistency.\n",
    "    \"\"\"\n",
    "    prompt = GRADE_PROMPT.format(question=question, context=context)\n",
    "    resp = grader_model.with_structured_output(GradeDocuments).invoke(\n",
    "        [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return 1 if resp.binary_score == \"yes\" else 0\n",
    "\n",
    "\n",
    "def evaluate_ndcg(queries: List[str], k: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate NDCG@k over a set of queries using the current retriever and LLM-based binary labels.\n",
    "    Returns a dict with mean NDCG and per-query breakdown.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for q in queries:\n",
    "        docs = retriever.get_relevant_documents(q)\n",
    "        relevances = [grade_binary(q, d.page_content) for d in docs]\n",
    "        scores.append(ndcg_at_k(relevances, k))\n",
    "    return {\n",
    "        \"k\": k,\n",
    "        \"num_queries\": len(queries),\n",
    "        \"ndcg@k_mean\": float(np.mean(scores)) if scores else 0.0,\n",
    "        \"per_query\": scores,\n",
    "    }\n",
    "\n",
    "\n",
    "# Example local evaluation set (kept small for fast local run)\n",
    "queries = [\n",
    "    \"What was the challange in the selection Principles of the Most Relevant Surveys?\",\n",
    "    \"What stages of agent communication are discussed?\",\n",
    "    \"How many types of relevant surveys are there?\",\n",
    "    \"Which figure illustrates a typical architecture of LLM-driven agents?\",\n",
    "    \"Do agents have worse security than LLMs?\",\n",
    "]\n",
    "ndcg_report = evaluate_ndcg(queries, k=5)\n",
    "print(\"NDCG@5 report:\", ndcg_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
